{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f97ae051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import random\n",
    "\n",
    "from models.persona_extractor import PersonaExtractor\n",
    "from dataset.msc_summary import MSC_Turns, extra_tokens\n",
    "from dataset.vocab import Vocab, PAD_TOKEN, START_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "456564fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# this ensures that the current MacOS version is at least 12.3+\n",
    "print(torch.backends.mps.is_available())\n",
    "\n",
    "# this ensures that the current current PyTorch installation was built with MPS activated.\n",
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d28e0b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/FrankVerhoef/Programming/PEX\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ddc7ac59",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b21723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5771b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab()\n",
    "traindata = MSC_Turns(args.datadir + args.traindata, vocab.text2vec, len_context=2, max_samples=args.train_samples)\n",
    "vocab.add_special_tokens(extra_tokens)\n",
    "vocab.add_to_vocab(traindata.corpus())\n",
    "vocab.cut_vocab(max_tokens=args.vocab_size)\n",
    "\n",
    "encoder_opts = {\n",
    "    \"input_size\": len(vocab),\n",
    "    \"embedding_size\": args.embedding_size,\n",
    "    \"hidden_size\": args.hidden_size,\n",
    "    \"aggregate_method\": args.aggregate_method\n",
    "}\n",
    "decoder_opts = {\n",
    "    \"input_size\": len(vocab),\n",
    "    \"embedding_size\": args.embedding_size,\n",
    "    \"hidden_size\": {\n",
    "        \"mean\": args.embedding_size,\n",
    "        \"lstm\": args.hidden_size,\n",
    "        \"bilstm\": args.hidden_size * 2,\n",
    "        \"poolbilstm\": args.hidden_size * 2            \n",
    "    }[args.encoder],\n",
    "    \"output_size\": len(vocab)\n",
    "}\n",
    "model = PersonaExtractor(args.encoder, encoder_opts, args.decoder, decoder_opts, start_token=vocab.tok2ind[START_TOKEN])\n",
    "\n",
    "if args.device == \"mps\":\n",
    "    assert torch.backends.mps.is_available(), \"Device 'mps' not available\"\n",
    "    assert torch.backends.mps.is_built(), \"PyTorch installation was not built with MPS activated\"\n",
    "elif args.device == \"cuda\":\n",
    "    assert torch.cuda.is_available(), \"Cuda not available\"\n",
    "\n",
    "wandb.init(project=\"pex\", entity=\"thegist\")\n",
    "wandb.config.update(args)  # Converts args to a dictionary and logs it in wandb\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=traindata, batch_size=args.batch_size, shuffle=True, collate_fn=traindata.batchify)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=testdata, batch_size=args.batch_size, shuffle=True, collate_fn=testdata.batchify)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.learning_rate)\n",
    "criterion = nn.NLLLoss(ignore_index=vocab.tok2ind[PAD_TOKEN], reduction='mean')\n",
    "\n",
    "best_model, train_stats = train(\n",
    "    model, train_loader, optimizer, criterion,\n",
    "    device=args.device, epochs=args.epochs, log_interval=args.log_interval\n",
    ")\n",
    "\n",
    "test_stats = test(\n",
    "    model, test_loader, criterion,\n",
    "    device=args.device\n",
    ")\n",
    "print(\"Test stats: \", test_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24f00cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/Users/FrankVerhoef/Programming/PEX/data/msc/msc_personasummary/session_1/train.txt'\n",
    "msc_turns = MSC_Turns(datapath, len_context=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b54b89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<P0> I need some advice on where to go on vacation, have you been anywhere lately? <P1> I have been all over the world. I'm military. <EOS>\n",
      "I served or serve in the military. I've traveled the world. <EOS>\n",
      "----------------------------------------\n",
      "<P0> I have been all over the world. I'm military. <P1> That is good you have alot of travel experience <EOS>\n",
      "<EOS>\n",
      "----------------------------------------\n",
      "<P0> That is good you have alot of travel experience <P1> Sure do. And a lot of experience blowing things up! Haha. Bora bora is nice. <EOS>\n",
      "I've blown things up. <EOS>\n",
      "----------------------------------------\n",
      "<P0> Sure do. And a lot of experience blowing things up! Haha. Bora bora is nice. <P1> I've been working non stop crazy hours and need a break. <EOS>\n",
      "I've been working a lot of extra hours. I want to break from my non-stop work. <EOS>\n",
      "----------------------------------------\n",
      "<P0> I've been working non stop crazy hours and need a break. <P1> The best breaks are spent with cute cuddly kittens. <EOS>\n",
      "<EOS>\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(msc_turns[i][0])\n",
    "    print(msc_turns[i][1])\n",
    "    print('-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26f8f9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank vacation announcer announcer computer computer catch seeking Both Both\n",
      "I love chocolate . <EOS>\n",
      "----------------------------------------\n",
      "3 Thank announcer computer catch seeking Both Both Both Both\n",
      "I love brownies . <EOS>\n",
      "----------------------------------------\n",
      "Thank doing doing wheelchair sick sick Went 2 computer computer\n",
      "<EOS>\n",
      "----------------------------------------\n",
      "Thank announcer computer computer sleep work computer computer sleep work\n",
      "I have an exam soon . <EOS>\n",
      "----------------------------------------\n",
      "3 Thank fact announcer announcer computer catch seeking Both Both\n",
      "I have three dogs . <EOS>\n",
      "----------------------------------------\n",
      "Thank doing doing wheelchair sick sick Went 2 computer computer\n",
      "I finish school in September . I do n't have any dogs . <EOS>\n",
      "----------------------------------------\n",
      "Thank doing only sick lessons Both Both Both Both Both\n",
      "<EOS>\n",
      "----------------------------------------\n",
      "Thank doing only sick lessons Both Both Both Both Both\n",
      "I plan on getting a job in teaching . <EOS>\n",
      "----------------------------------------\n",
      "3 Thank fact announcer announcer computer catch seeking Both Both\n",
      "I play the drums . <EOS>\n",
      "----------------------------------------\n",
      "3 shop computer sleep sleep work computer computer sleep work\n",
      "<EOS>\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset = MSC_Summaries(datapath, len_context=2, tokenizer=nlp, tok2ind=tok2ind)\n",
    "\n",
    "for i in range(10,20):\n",
    "    _, hidden = encode(dataset[i][0])\n",
    "#     dec_out = decode(hidden, dataset[i][1], teacher_forcing=True)\n",
    "    dec_out = decode(hidden)\n",
    "    dec = torch.transpose(dec_out.argmax(dim=-1), 1, 0)[0]\n",
    "    response = ' '.join([ind2tok[i] for i in dec])\n",
    "    print(response)\n",
    "    print(' '.join(vec2tok(dataset[i][1])))\n",
    "    print('-' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18625a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "def train_step(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    _, hidden = encode(input_tensor)\n",
    "    decoder_output = decode(hidden, target=target_tensor, teacher_forcing=True, max=target_tensor.size(0))\n",
    "    loss = criterion(decoder_output.squeeze(), target_tensor.squeeze())\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bddd31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(encoder, decoder, dataset, max_steps=1000, print_every=1000, learning_rate=0.01):\n",
    "\n",
    "    print_loss_total = 0\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for step, (x, y) in enumerate(dataset):\n",
    "\n",
    "        loss = train_step(x.view(-1, 1), y.view(-1, 1), encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "\n",
    "        if (step + 1) % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print(step + 1, print_loss_avg)\n",
    "            print_loss_total = 0\n",
    "        if step >= max_steps: break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "63b0d30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 6.422246384620666\n",
      "200 4.743728432059288\n",
      "300 4.321910395920277\n",
      "400 3.416451494693756\n",
      "500 3.403665184676647\n",
      "600 2.8189416801929474\n",
      "700 3.0073387691378595\n",
      "800 2.5979190544784068\n",
      "900 2.6689348646998408\n",
      "1000 2.6499454717338087\n"
     ]
    }
   ],
   "source": [
    "train(encoder, decoder, dataset, max_steps=1000, print_every=100, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e0765fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6227a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = torch.randn(3,5)\n",
    "t = torch.tensor([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5b8b7065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4610)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(o,t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
