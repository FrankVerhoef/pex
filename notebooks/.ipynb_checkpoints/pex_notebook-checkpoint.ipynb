{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8020acd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c67ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# this ensures that the current MacOS version is at least 12.3+\n",
    "print(torch.backends.mps.is_available())\n",
    "\n",
    "# this ensures that the current current PyTorch installation was built with MPS activated.\n",
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "b8dedbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "563d6ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSC_Turns(Dataset):\n",
    "    \n",
    "    def __init__(self, path, len_context=2):\n",
    "        dialogues = []\n",
    "        with open(path, \"r\") as f:\n",
    "            for line in f:\n",
    "                dialogues.append(json.loads(line))\n",
    "        self.len_context = len_context\n",
    "        self.turns, self.personas = self.transform(dialogues)\n",
    "        \n",
    "    def transform(self, dialogues):\n",
    "        turns, personas = [], []\n",
    "        \n",
    "        for d in dialogues:\n",
    "            for i in range(len(d[\"dialog\"]) - self.len_context + 1):\n",
    "                turns.append(' '.join([\n",
    "                    '<P{}> '.format((self.len_context - j) % 2) + d[\"dialog\"][i+j].get(\"text\",\"\")\n",
    "                    for j in range(self.len_context)\n",
    "                ]) + ' <EOS>')\n",
    "                personas.append('<SOS> ' + d[\"dialog\"][i+self.len_context-1].get(\"persona_text\",\"\") + ' <EOS>')\n",
    "        \n",
    "        return turns, personas\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(turns)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.turns[i], self.personas[i]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "d632c64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/Users/FrankVerhoef/Programming/PEX/data/msc/msc_personasummary/session_1/train.txt'\n",
    "dataset = MSC_Turns(datapath, len_context=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "c7d929ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<P0> I need some advice on where to go on vacation, have you been anywhere lately? <P1> I have been all over the world. I'm military. <EOS> \n",
      "\t <SOS> I served or serve in the military. I've traveled the world. <EOS>\n",
      "----------------------------------------\n",
      "<P0> I have been all over the world. I'm military. <P1> That is good you have alot of travel experience <EOS> \n",
      "\t <SOS>  <EOS>\n",
      "----------------------------------------\n",
      "<P0> That is good you have alot of travel experience <P1> Sure do. And a lot of experience blowing things up! Haha. Bora bora is nice. <EOS> \n",
      "\t <SOS> I've blown things up. <EOS>\n",
      "----------------------------------------\n",
      "<P0> Sure do. And a lot of experience blowing things up! Haha. Bora bora is nice. <P1> I've been working non stop crazy hours and need a break. <EOS> \n",
      "\t <SOS> I've been working a lot of extra hours. I want to break from my non-stop work. <EOS>\n",
      "----------------------------------------\n",
      "<P0> I've been working non stop crazy hours and need a break. <P1> The best breaks are spent with cute cuddly kittens. <EOS> \n",
      "\t <SOS>  <EOS>\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(dataset[i][0], '\\n\\t', dataset[i][1])\n",
    "    print('-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "414b0969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.symbols import ORTH\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable = ['ner', 'tagger', 'parser', 'textcat'])\n",
    "special_tokens = ['<P0>', '<P1>', '<SOS>', '<EOS>']\n",
    "for t in special_tokens:\n",
    "    nlp.tokenizer.add_special_case(t, [{ORTH: t}])\n",
    "# nlp.tokenizer.add_special_case(\"<P1>\", [{ORTH: \"<P1>\"}])\n",
    "# nlp.tokenizer.add_special_case(\"<SOS>\", [{ORTH: \"<SOS>\"}])\n",
    "# nlp.tokenizer.add_special_case(\"<EOS>\", [{ORTH: \"<EOS>\"}])\n",
    "\n",
    "\n",
    "def build_dict(dataset, max=1000):\n",
    "    vocab = {t: 0 for t in special_tokens}\n",
    "    for turn, persona in dataset: \n",
    "        tokens = nlp(turn.replace(SEP, ' ') + ' ' + persona)\n",
    "        for t in tokens:\n",
    "            if t.text in vocab.keys():\n",
    "                vocab[t.text] += 1\n",
    "            else:\n",
    "                vocab[t.text] = 1\n",
    "        if len(vocab.keys()) >= max: break\n",
    "    vocab = dict(sorted(vocab.items(), key=lambda item: item[1], reverse=True))\n",
    "    return list(vocab.keys())[:max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "a3fbe9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "ind2tok = build_dict(dataset, max=100)\n",
    "tok2ind = {token: i for i, token in enumerate(ind2tok)}\n",
    "print(len(ind2tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "0249a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embed = self.embedding(x).view(1, 1, -1)\n",
    "        output, hidden_new = self.gru(embed, hidden)\n",
    "        return output, hidden_new\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        output = self.embedding(x).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden_new = self.gru(output, hidden)\n",
    "#         print(\"after gru\", output.shape, hidden.shape)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden_new\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "d30c669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(len(ind2tok), 30)\n",
    "decoder = DecoderRNN(30, len(ind2tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "4f992792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(txt):\n",
    "\n",
    "    tokens = nlp(txt)\n",
    "    x = torch.tensor([[tok2ind[t.text] for t in tokens]]).view(-1, 1)\n",
    "    hidden = encoder.initHidden()\n",
    "    for i in range(x.size(0)):\n",
    "        output, hidden = encoder(x[i], hidden)\n",
    "        \n",
    "    return output, hidden\n",
    "\n",
    "def decode(hidden, max=10):\n",
    "    \n",
    "    out = [torch.tensor(tok2ind['<SOS>']).expand((1, hidden.size(1)))]\n",
    "    print(out[0].shape)\n",
    "    for i in range(max):\n",
    "        output, hidden = decoder(out[i], hidden)\n",
    "        out.append(output.argmax(dim=-1).view(1, -1))\n",
    "        \n",
    "    return torch.stack(out).reshape(-1, hidden.size(1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "d85d48a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 5, 5, 5, 5]])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(tok2ind['<SOS>']).expand((1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "763a19d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5],\n",
       "        [32],\n",
       "        [32],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [55],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [55]])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, hidden = encode(dataset[0][0])\n",
    "# print(hidden)\n",
    "decode(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "fc9a81ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<P0> I need some advice on where to go on vacation, have you been anywhere lately? <P1> I have been all over the world. I'm military. <EOS>"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "286a536b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.5622,  0.0769, -0.1982, -0.1896, -0.1135,  0.0275, -0.2680,\n",
       "            0.2536,  0.4733, -0.2965,  0.2573, -0.1058,  0.4197,  0.0090,\n",
       "            0.2862,  0.0765, -0.5041,  0.1662, -0.1802, -0.2255, -0.2184,\n",
       "           -0.0524,  0.0231, -0.1099,  0.0892,  0.1154,  0.3975, -0.4090,\n",
       "            0.4074, -0.1861]]], grad_fn=<StackBackward0>),\n",
       " tensor([[[ 0.5622,  0.0769, -0.1982, -0.1896, -0.1135,  0.0275, -0.2680,\n",
       "            0.2536,  0.4733, -0.2965,  0.2573, -0.1058,  0.4197,  0.0090,\n",
       "            0.2862,  0.0765, -0.5041,  0.1662, -0.1802, -0.2255, -0.2184,\n",
       "           -0.0524,  0.0231, -0.1099,  0.0892,  0.1154,  0.3975, -0.4090,\n",
       "            0.4074, -0.1861]]], grad_fn=<StackBackward0>))"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e22d658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
