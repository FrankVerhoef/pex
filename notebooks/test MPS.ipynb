{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f97ae051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import random\n",
    "\n",
    "from models.persona_extractor import PersonaExtractor\n",
    "from dataset.msc_summary import MSC_Turns, extra_tokens\n",
    "from dataset.vocab import Vocab, PAD_TOKEN, START_TOKEN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "456564fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# this ensures that the current MacOS version is at least 12.3+\n",
    "print(torch.backends.mps.is_available())\n",
    "\n",
    "# this ensures that the current current PyTorch installation was built with MPS activated.\n",
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63ffc3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = torch.rand(16, 10).to(\"mps\"), torch.rand(16, 1).to(\"mps\")\n",
    "model = nn.Linear(10, 1).to(\"mps\")\n",
    "criterion = nn.L1Loss() # nn.KLDivLoss()\n",
    "loss = criterion(model(X), y)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59f097ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'datadir': '/Users/FrankVerhoef/Programming/PEX/data/',\n",
    "    'traindata': 'msc/msc_personasummary/session_1/train.txt',\n",
    "    'train_samples': 1000,\n",
    "    'vocab_size': 2000,\n",
    "    'embedding_size': 16,\n",
    "    'hidden_size': 32,\n",
    "    'aggregate_method': 'cpu',\n",
    "    'encoder': 'lstm',\n",
    "    'decoder': 'lstm',\n",
    "    'device': 'mps',\n",
    "    'batch_size': 8,\n",
    "    'learning_rate': 0.01,\n",
    "    'epochs': 1,\n",
    "    'log_interval': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aacb629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 3913.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 2930 tokens to vocabulary\n",
      "Reduced vocab to 2000 tokens, covering 97.0% of corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocab()\n",
    "traindata = MSC_Turns(args['datadir'] + args['traindata'], vocab.text2vec, len_context=2, max_samples=args['train_samples'])\n",
    "vocab.add_special_tokens(extra_tokens)\n",
    "vocab.add_to_vocab(traindata.corpus())\n",
    "vocab.cut_vocab(max_tokens=args['vocab_size'])\n",
    "\n",
    "encoder_opts = {\n",
    "    \"input_size\": len(vocab),\n",
    "    \"embedding_size\": args['embedding_size'],\n",
    "    \"hidden_size\": args['hidden_size'],\n",
    "    \"aggregate_method\": args['aggregate_method']\n",
    "}\n",
    "decoder_opts = {\n",
    "    \"input_size\": len(vocab),\n",
    "    \"embedding_size\": args['embedding_size'],\n",
    "    \"hidden_size\": {\n",
    "        \"mean\": args['embedding_size'],\n",
    "        \"lstm\": args['hidden_size'],\n",
    "        \"bilstm\": args['hidden_size'] * 2,\n",
    "        \"poolbilstm\": args['hidden_size'] * 2            \n",
    "    }[args['encoder']],\n",
    "    \"output_size\": len(vocab)\n",
    "}\n",
    "model = PersonaExtractor(args['encoder'], encoder_opts, args['decoder'], decoder_opts, start_token=vocab.tok2ind[START_TOKEN])\n",
    "\n",
    "if args['device'] == \"mps\":\n",
    "    assert torch.backends.mps.is_available(), \"Device 'mps' not available\"\n",
    "    assert torch.backends.mps.is_built(), \"PyTorch installation was not built with MPS activated\"\n",
    "elif args['device'] == \"cuda\":\n",
    "    assert torch.cuda.is_available(), \"Cuda not available\"\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=traindata, batch_size=args['batch_size'], shuffle=True, collate_fn=traindata.batchify)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args['learning_rate'])\n",
    "criterion = nn.NLLLoss(ignore_index=vocab.tok2ind[PAD_TOKEN], reduction='mean')\n",
    "device = args['device']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b75cc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PersonaExtractor(\n",
       "  (encoder): UniLSTM(\n",
       "    (embed): Embedding(2004, 16)\n",
       "    (lstm): LSTM(16, 32, batch_first=True)\n",
       "  )\n",
       "  (decoder): LSTM(\n",
       "    (embed): Embedding(2004, 16)\n",
       "    (lstm): LSTM(16, 32, batch_first=True)\n",
       "    (out): Linear(in_features=32, out_features=2004, bias=True)\n",
       "    (softmax): LogSoftmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2830e22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next((iter(train_loader)))\n",
    "xs, ys, xs_len, ys_len = batch\n",
    "xs = xs.to(device)\n",
    "ys = ys.to(device)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "output = model(xs, xs_len, teacher_forcing=True, ys=ys)\n",
    "loss = criterion(output.transpose(1,2), ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18d3ad85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.6256, device='mps:0', grad_fn=<NllLoss2DBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/frankverhoef/opt/miniconda3/envs/pex/lib/python3.9/site-packages/torch/_tensor_str.py:115: UserWarning: The operator 'aten::nonzero' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1670525473998/work/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  nonzero_finite_vals = torch.masked_select(\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290a8da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58704fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cffafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, train_stats = train(\n",
    "    model, train_loader, optimizer, criterion,\n",
    "    device=args['device'], epochs=args['epochs'], log_interval=args['log_interval']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54b89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(msc_turns[i][0])\n",
    "    print(msc_turns[i][1])\n",
    "    print('-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02b9333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch, model, optimizer, criterion, device):\n",
    "\n",
    "    xs, ys, xs_len, ys_len = batch\n",
    "    xs = xs.to(device)\n",
    "    ys = ys.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(xs, xs_len, teacher_forcing=True, ys=ys)\n",
    "    loss = criterion(output.transpose(1,2), ys)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "def train(model, dataloader, optimizer, criterion, device=\"cpu\", epochs=1, log_interval=1000):\n",
    "\n",
    "    losses = []\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for step, batch in enumerate(iter(dataloader)):\n",
    "\n",
    "            loss = train_step(batch, model, optimizer, criterion, device)\n",
    "            losses.append(loss)\n",
    "\n",
    "            if (step + 1) % log_interval == 0:\n",
    "                loss_avg = sum(losses[-log_interval:]) / log_interval\n",
    "                wandb.log({\n",
    "                    \"train_loss\": loss_avg\n",
    "                })\n",
    "                print(\"Epoch {}, step {}: loss={}\".format(epoch, step+1, loss_avg))\n",
    "    \n",
    "    return model, {\"train_loss\": losses}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5cc1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
