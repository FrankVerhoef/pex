{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from models.bart_extractor import BartExtractor, ConditionalFactLoss\n",
    "from dataset.msc_summary_turns import MSC_Turns\n",
    "from dataset.msc_summary import MSC_Summaries\n",
    "from metrics.terp import TerpMetric\n",
    "\n",
    "import utils.logging as logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-21 23:49:12,019 INFO     | Loading model from /Users/FrankVerhoef/Programming/PEX/checkpoints/trained_bart\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.set_log_level(logging.SPAM)\n",
    "\n",
    "# Settings for dataset\n",
    "datadir = '/Users/FrankVerhoef/Programming/PEX/data/'\n",
    "basedir = 'msc/msc_personasummary/'\n",
    "sessions = [1]\n",
    "len_context = 2\n",
    "speaker_prefixes = [\"<other>\", \"<self>\"]\n",
    "nofact_token = '<nofact>'\n",
    "add_tokens = speaker_prefixes + [nofact_token]\n",
    "test_samples = 20\n",
    "subset = 'train'\n",
    "\n",
    "# config for TerpMetric\n",
    "JAVA_HOME = \"/opt/homebrew/opt/openjdk/libexec/openjdk.jdk/Contents/Home\"\n",
    "TERPDIR = \"/Users/FrankVerhoef/Programming/terp/\"\n",
    "TMPDIR = \"/Users/FrankVerhoef/Programming/PEX/output/\"\n",
    "TerpMetric.set(terp_dir=TERPDIR, java_home=JAVA_HOME, tmp_dir=TMPDIR)\n",
    "\n",
    "# Settings for model\n",
    "checkpoint_dir = '/Users/FrankVerhoef/Programming/PEX/checkpoints/'\n",
    "load = 'trained_bart'\n",
    "\n",
    "# Setup\n",
    "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "if add_tokens is not None:\n",
    "    num_added_toks = tokenizer.add_tokens(add_tokens)\n",
    "nofact_token_id = tokenizer.convert_tokens_to_ids(nofact_token) if nofact_token != '' else tokenizer.eos_token_id\n",
    "assert nofact_token_id != tokenizer.unk_token_id, \"nofact_token '{}' must be known token\".format(nofact_token)\n",
    "\n",
    "model = BartExtractor(bart_base='facebook/bart-large-cnn', nofact_token_id=nofact_token_id)\n",
    "model.bart.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "MSC_Turns.set(tokenizer=tokenizer, len_context=len_context, speaker_prefixes=speaker_prefixes, nofact_token=nofact_token)\n",
    "msc_turns = MSC_Turns(basedir=datadir + basedir, sessions=sessions, subset=subset, max_samples=10)\n",
    "\n",
    "logging.info(\"Loading model from {}\".format(checkpoint_dir + load))\n",
    "model.load_state_dict(torch.load(checkpoint_dir + load, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.bart.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.bart.generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<self>I do not, I like to dance though <other>Dancing is cool. I dance when I work out sometimes.', 'I like to dance and work out.')\n",
      "('<self>Absolutely, last time I was in a mall was for senior prom photos! <other>Wow. Where are you from?', '<nofact>')\n",
      "('<self>Where do you want to visit? <other>Anywhere with a lot of hiking trails!', '<nofact>')\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(msc_turns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-18 23:42:55,529 INFO     | Evaluating model on 10 samples of testdata in msc/msc_personasummary/ with arguments {'device': 'cpu', 'log_interval': 10, 'decoder_max': 20}\n",
      "2023-05-18 23:42:57,287 SPAM     | Generate: pred_fact=tensor([True])\n",
      "2023-05-18 23:42:57,288 SPAM     | Generate: gen_out=tensor([[   2,    0,    0,    0,  100,   33,   57,   11,    5,  831,    4,   38,\n",
      "           21,   11,    5, 3835,   77,   38,   21, 3240,    2]])\n",
      "context:     <self>My mother work as a nurse <other>Have you ever been in the military? I was when I was younger\n",
      "target:      I was in the military when I was young.\n",
      "prediction:  I have been in the military. I was in the army when I was younger\n",
      "----------------------------------------\n",
      "2023-05-18 23:42:58,329 SPAM     | Generate: pred_fact=tensor([True])\n",
      "2023-05-18 23:42:58,330 SPAM     | Generate: gen_out=tensor([[   2,    0,    0,    0,  100,  173,  608, 4861,  751,    4,    2]])\n",
      "context:     <self>It is working with kids, yours <other>I work doing maintenance outside, daydreaming about a better job\n",
      "target:      I work doing maintenance. I would like to do a different job.\n",
      "prediction:  I work doing maintenance outside.\n",
      "----------------------------------------\n",
      "2023-05-18 23:42:59,583 SPAM     | Generate: pred_fact=tensor([True])\n",
      "2023-05-18 23:42:59,584 SPAM     | Generate: gen_out=tensor([[    2,     0,     0,     0,   100,   524,  7758,    23,   127, 37966,\n",
      "           254,     4,     2]])\n",
      "context:     <self>Hello! How are you doing? <other>Good. I'm really mad at my coworker.\n",
      "target:      <nofact>\n",
      "prediction:  I am mad at my coworker.\n",
      "----------------------------------------\n",
      "2023-05-18 23:43:01,157 SPAM     | Generate: pred_fact=tensor([True])\n",
      "2023-05-18 23:43:01,158 SPAM     | Generate: gen_out=tensor([[   2,    0,    0,    0,  100,   33,   10, 1141,    4,   38,   33,   10,\n",
      "         2761,    4,    2]])\n",
      "context:     <self>Yes, a few with my sister. You? <other>Yes, a few too. The first time I ever saw my wife was at a tickleback concert\n",
      "target:      I met my wife at a tickleback concert.\n",
      "prediction:  I have a wife. I have a sister.\n",
      "----------------------------------------\n",
      "2023-05-18 23:43:01,724 SPAM     | Generate: pred_fact=tensor([False])\n",
      "2023-05-18 23:43:01,724 SPAM     | Generate: gen_out=tensor([[    2,     0,     0,     0, 50267,     2]])\n",
      "context:     <self>I've the most amazing view of the sunset from my new apartment! <other>I'm so jealous. I've to drive out to the country to see a good one\n",
      "target:      I don't live in the country.\n",
      "prediction:  <nofact>\n",
      "----------------------------------------\n",
      "2023-05-18 23:43:03,113 SPAM     | Generate: pred_fact=tensor([True])\n",
      "2023-05-18 23:43:03,114 SPAM     | Generate: gen_out=tensor([[    2,     0,     0,     0,   100,    33,    10,   181,  3252,  9240,\n",
      "         15696,     4,    38,   524,    41,  3025,     4,     2]])\n",
      "context:     <self>What do you do for fun? I am an artist. <other>I play with my pug corgi.\n",
      "target:      I have a dog.\n",
      "prediction:  I have a pug corgi. I am an artist.\n",
      "----------------------------------------\n",
      "2023-05-18 23:43:03,458 SPAM     | Generate: pred_fact=tensor([False])\n",
      "2023-05-18 23:43:03,459 SPAM     | Generate: gen_out=tensor([[    2,     0, 50267,     2]])\n",
      "context:     <self>I do love japan! I cannot wait to go! <other>Maybe I could help you learn japanese.\n",
      "target:      <nofact>\n",
      "prediction:  <nofact>\n",
      "----------------------------------------\n",
      "2023-05-18 23:43:04,342 SPAM     | Generate: pred_fact=tensor([True])\n",
      "2023-05-18 23:43:04,343 SPAM     | Generate: gen_out=tensor([[   2,    0,    0,    0,  100,  101,    7, 4806,    4,    2]])\n",
      "context:     <self>Sounds like a lot of fun, what else do you like? <other>I like biking a lot it is fun\n",
      "target:      I enjoy biking.\n",
      "prediction:  I like to bike.\n",
      "----------------------------------------\n",
      "2023-05-18 23:43:04,697 SPAM     | Generate: pred_fact=tensor([False])\n",
      "2023-05-18 23:43:04,698 SPAM     | Generate: gen_out=tensor([[    2,     0, 50267,     2]])\n",
      "context:     <self>I want to get a nice car and drive the coast <other>That sounds like it would be a lot of fun!\n",
      "target:      <nofact>\n",
      "prediction:  <nofact>\n",
      "----------------------------------------\n",
      "2023-05-18 23:43:07,012 SPAM     | Generate: pred_fact=tensor([True])\n",
      "2023-05-18 23:43:07,013 SPAM     | Generate: gen_out=tensor([[    2,     0,     0,     0,   100,   657,  6087, 31599,  7150,   268,\n",
      "             4,    38,   524,    41, 24408,     4,     2]])\n",
      "context:     <self>I work with my mother. She's a professional makeup artist <other>Cool. I'm an accountant. Who loves to eat raw hamburgers.\n",
      "target:      I am an accountant.\n",
      "prediction:  I love raw hamburgers. I am an accountant.\n",
      "----------------------------------------\n",
      "2023-05-18 23:43:07,014 VERBOSE  | Evaluated 10/10 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-18 23:43:14,421 SPAM     | TERp output\n",
      "Loading parameters from /Users/FrankVerhoef/Programming/terp/data/terpa.param\n",
      "Loading parameters from /Users/FrankVerhoef/Programming/terp/data/data_loc.param\n",
      "\"/Users/FrankVerhoef/Programming/PEX/output/hyp.trans\" was successfully parsed as Trans text\n",
      "\"/Users/FrankVerhoef/Programming/PEX/output/ref.trans\" was successfully parsed as Trans text\n",
      "Creating Segment Phrase Tables From DB\n",
      "Processing [sys][000000][000000]\n",
      "Processing [sys][000000][000001]\n",
      "Processing [sys][000000][000002]\n",
      "Processing [sys][000000][000003]\n",
      "Processing [sys][000000][000004]\n",
      "Processing [sys][000000][000005]\n",
      "Finished Calculating TERp\n",
      "Total TER: 0,63 (29,48 / 47,00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# config for TerpMetric\n",
    "JAVA_HOME = \"/opt/homebrew/opt/openjdk/libexec/openjdk.jdk/Contents/Home\"\n",
    "TERPDIR = \"/Users/FrankVerhoef/Programming/terp/\"\n",
    "TMPDIR = \"/Users/FrankVerhoef/Programming/PEX/output/\"\n",
    "TerpMetric.set(terp_dir=TERPDIR, java_home=JAVA_HOME, tmp_dir=TMPDIR)\n",
    "\n",
    "eval_kwargs = {'device': 'cpu', 'log_interval': 10, 'decoder_max': 20}\n",
    "\n",
    "logging.info(\"Evaluating model on {} samples of testdata in {} with arguments {}\".format(len(msc_turns), basedir, eval_kwargs))\n",
    "eval_stats = msc_turns.evaluate(model, **eval_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.800000011920929,\n",
       " 'f1': 0.8571428656578064,\n",
       " 'precision': 0.8571428656578064,\n",
       " 'recall': 0.8571428656578064,\n",
       " 'cm': [[2, 1], [1, 6]],\n",
       " 'bleu_2': 0.3472660183906555,\n",
       " 'bleu_4': 0.2208770364522934,\n",
       " 'bert_f1': 0.6035879502693812,\n",
       " 'terp': 0.5634329319000244,\n",
       " 'rouge1_fmeasure': 0.48769572377204895,\n",
       " 'rouge1_precision': 0.465277761220932,\n",
       " 'rouge1_recall': 0.6134259104728699,\n",
       " 'rouge2_fmeasure': 0.3181818425655365,\n",
       " 'rouge2_precision': 0.3095238208770752,\n",
       " 'rouge2_recall': 0.4482323229312897,\n",
       " 'rougeL_fmeasure': 0.47380685806274414,\n",
       " 'rougeL_precision': 0.4541666507720947,\n",
       " 'rougeL_recall': 0.5949074029922485}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSC_Summaries.set(tokenizer=tokenizer, speaker_prefixes=speaker_prefixes, nofact_token=nofact_token)\n",
    "msc_summaries = MSC_Summaries(\n",
    "    basedir=datadir + basedir, \n",
    "    session=1, \n",
    "    subset=\"test\",   \n",
    "    max_samples=test_samples      \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['<other> Hi, tracy here. I love people and fast cars. You sing? <self> Hi tracy. Amanda here. I enjoy going to the gym alongside my vegan diet.', \"<other> I see. I love being helpful and I paint art. Are you an artist? <self> I don't sing, but love art. My lawyer husband is an artist as well.\", '<other> Get out! I am a paralegal. I love helping people too. You bake? <self> Whoa! Funny you say that, my jeep is loaded with baked goods right now!', '<other> Great! I would love to paint that picture. You dance? <self> If you call zumba dancing! Lol! What is your favorite vacations spot?', '<other> Niagra falls. It is an artist paradise. You like to travel? <self> I love traveling, especially to the mountains. They are a good workout!', '<other> Me too! I like fast cars and new people. Nice to meet you. <self> You as well. I love vehicles that can tackle rough terrain, like my jeep wrangler.'], 'My name is Amanda.\\nI enjoy going to the gym.\\nI am a vegan.\\nI have a husband who is a lawyer and also loves art.\\nI am not a singer.\\nI love art.\\nI have a Jeep.\\nI am a baker.\\nI do zumba.\\nI love traveling in the mountains for the exercise.\\nI love vehicles that handle rough terrain.')\n",
      "([\"<other> Hey, how are you doing today? <self> I'm doing fantastic! Just got mexican food for lunch..\", \"<other> That's awesome. My grandkids love mexican food. <self> How many grand kids do you have? Are they tall?\", \"<other> I have 12 grandkids. I usually see them when I'm at church. <self> Do they like dogs? My dogs name is drunky. He loves kids..\", '<other> They do! I love dogs too, mine sits with me while I read. <self> I like to stretch when I read. I can even touch my toes to my nose..', \"<other> Oh, man that's crazy! I love going barefoot to the lake near me. <self> I am pretty tall to I have large feet, so that helps. Love going barefoot..\", '<other> What do you like to do in your spare time. <self> I like to take a drive with my dog drunky in my subaru legacy.', '<other> Nice, I like to be at church worshipping god with family and friends. <self> That sounds fantastic. Religion is something my parents taught me growing up..'], \"I had Mexican food for lunch today.\\nI have a dog named Drunky.\\nI like to stretch while reading.\\nI can touch my toes to my nose.\\nI love going barefoot.\\nI'm tall and have big feet.\\nI have a Subaru Legacy.\\nI like going for drives with my dog.\\nI was brought up religious.\")\n",
      "(['<other> Good morning what are you up to? <self> Good morning to you as well. I just got up and spent some time wiht my kids. And you?', '<other> Hanging out with my brother in law, my sister just got married. <self> Oh thats nice. My cousin just got married. They had a beach wedding which was great.', '<other> Sounds beautiful.. Gotta get to work soon, ugh fast food industry. <self> No fun at all. Luckily work is closed today so I just rolled out of bed.', '<other> Nice, I was up late watching movies. What movies do you like? <self> Like a specific genre or individual titles?', \"<other> Either lol.. I love comedies, but horror movies terrify me. <self> I can't watch horror movies. I am up all night. My kids however love them.\", '<other> Isnt that funny! I have to watch cartoons after anything scary. <self> I just cant watch them in general. For some reason my mind just goes into overdrive.', '<other> How old are your kid?. <self> 15. Do you have any?'], 'I have kids.\\nMy cousin recently got married at the beach.\\nI do not like horror movies.\\nMy kids love horror movies.\\nHorror movies makes my mind go into overdrive.')\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(msc_summaries[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-18 23:43:51,383 INFO     | Start evaluation of model BartExtractor on metrics: t,e,r\n",
      "2023-05-18 23:43:57,331 SPAM     | Generate: pred_fact=tensor([ True,  True, False,  True,  True,  True])\n",
      "2023-05-18 23:43:57,332 SPAM     | Generate: gen_out=tensor([[    2,     0,     0,     0,   100,   101,   164,     7,     5,  6545,\n",
      "             4,    38,  3529,    10, 15848,  5626,     4,     2,     1],\n",
      "        [    2,     0,     0,     0,   100,   657,  1808,     4,    38,   218,\n",
      "            75,  7884,     4,    38,    33,    10,  1623,     4,     2],\n",
      "        [    2,     0,     0,     0, 50267,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,     4,    38,   101,     7,  3836,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,   101,     7,  1504,     4,    38,\n",
      "           101,     7,   213,     7,     5,  9787,     4,     2,     1],\n",
      "        [    2,     0,     0,     0,   100,    33,    10,  4112,  2462, 14902,\n",
      "         32268,     4,     2,     1,     1,     1,     1,     1,     1]])\n",
      "Utterances: \n",
      "\t<other> Hi, tracy here. I love people and fast cars. You sing? <self> Hi tracy. Amanda here. I enjoy going to the gym alongside my vegan diet.\n",
      "\t<other> I see. I love being helpful and I paint art. Are you an artist? <self> I don't sing, but love art. My lawyer husband is an artist as well.\n",
      "\t<other> Get out! I am a paralegal. I love helping people too. You bake? <self> Whoa! Funny you say that, my jeep is loaded with baked goods right now!\n",
      "\t<other> Great! I would love to paint that picture. You dance? <self> If you call zumba dancing! Lol! What is your favorite vacations spot?\n",
      "\t<other> Niagra falls. It is an artist paradise. You like to travel? <self> I love traveling, especially to the mountains. They are a good workout!\n",
      "\t<other> Me too! I like fast cars and new people. Nice to meet you. <self> You as well. I love vehicles that can tackle rough terrain, like my jeep wrangler.\n",
      "Summary: \n",
      "\tMy name is Amanda.\n",
      "\tI enjoy going to the gym.\n",
      "\tI am a vegan.\n",
      "\tI have a husband who is a lawyer and also loves art.\n",
      "\tI am not a singer.\n",
      "\tI love art.\n",
      "\tI have a Jeep.\n",
      "\tI am a baker.\n",
      "\tI do zumba.\n",
      "\tI love traveling in the mountains for the exercise.\n",
      "\tI love vehicles that handle rough terrain.\n",
      "Prediction: \n",
      "\tI like going to the gym. I eat a vegan diet.\n",
      "\tI love art. I don't sing. I have a husband.\n",
      "\t<nofact>\n",
      "\t. I like to dance.\n",
      "\tI like to travel. I like to go to the mountains.\n",
      "\tI have a jeep wrangler.\n",
      "\n",
      "2023-05-18 23:44:02,184 SPAM     | Generate: pred_fact=tensor([False, False,  True,  True,  True,  True, False])\n",
      "2023-05-18 23:44:02,185 SPAM     | Generate: gen_out=tensor([[    2,     0,     0,     0, 50267,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,    33,    10,  2335,  1440, 12402,\n",
      "         25339,     4,     2,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,   101,     7,  4140,    77,    38,\n",
      "          1166,     4,     2,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,    33,   739,  1730,     4,    38,\n",
      "           524,  6764,     4,     2,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,    33,    10,  2335,  1440, 12402,\n",
      "         25339,     4,    38,  1305,    10,  2849, 21407,     4,     2],\n",
      "        [    2,     0,     0,     0, 50267,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1]])\n",
      "Utterances: \n",
      "\t<other> Hey, how are you doing today? <self> I'm doing fantastic! Just got mexican food for lunch..\n",
      "\t<other> That's awesome. My grandkids love mexican food. <self> How many grand kids do you have? Are they tall?\n",
      "\t<other> I have 12 grandkids. I usually see them when I'm at church. <self> Do they like dogs? My dogs name is drunky. He loves kids..\n",
      "\t<other> They do! I love dogs too, mine sits with me while I read. <self> I like to stretch when I read. I can even touch my toes to my nose..\n",
      "\t<other> Oh, man that's crazy! I love going barefoot to the lake near me. <self> I am pretty tall to I have large feet, so that helps. Love going barefoot..\n",
      "\t<other> What do you like to do in your spare time. <self> I like to take a drive with my dog drunky in my subaru legacy.\n",
      "\t<other> Nice, I like to be at church worshipping god with family and friends. <self> That sounds fantastic. Religion is something my parents taught me growing up..\n",
      "Summary: \n",
      "\tI had Mexican food for lunch today.\n",
      "\tI have a dog named Drunky.\n",
      "\tI like to stretch while reading.\n",
      "\tI can touch my toes to my nose.\n",
      "\tI love going barefoot.\n",
      "\tI'm tall and have big feet.\n",
      "\tI have a Subaru Legacy.\n",
      "\tI like going for drives with my dog.\n",
      "\tI was brought up religious.\n",
      "Prediction: \n",
      "\t<nofact>\n",
      "\t<nofact>\n",
      "\tI have a dog named drunky.\n",
      "\tI like to stretch when I read.\n",
      "\tI have large feet. I am tall.\n",
      "\tI have a dog named drunky. I drive a subaru.\n",
      "\t<nofact>\n",
      "\n",
      "2023-05-18 23:44:06,249 SPAM     | Generate: pred_fact=tensor([ True,  True, False, False,  True, False,  True])\n",
      "2023-05-18 23:44:06,250 SPAM     | Generate: gen_out=tensor([[    2,     0,     0,     0,   100,    33,  1159,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,    33,    10, 11204,    54,   300,\n",
      "          2997,     4,     2,     1,     1,     1],\n",
      "        [    2,     0,     0,     0, 50267,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,   524,  8265,     9,  8444,  4133,\n",
      "             4,    38,    33,  1159,     4,     2],\n",
      "        [    2,     0,     0,     0, 50267,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,    33,    10,   379,    12,   180,\n",
      "            12,   279,   979,     4,     2,     1]])\n",
      "Utterances: \n",
      "\t<other> Good morning what are you up to? <self> Good morning to you as well. I just got up and spent some time wiht my kids. And you?\n",
      "\t<other> Hanging out with my brother in law, my sister just got married. <self> Oh thats nice. My cousin just got married. They had a beach wedding which was great.\n",
      "\t<other> Sounds beautiful.. Gotta get to work soon, ugh fast food industry. <self> No fun at all. Luckily work is closed today so I just rolled out of bed.\n",
      "\t<other> Nice, I was up late watching movies. What movies do you like? <self> Like a specific genre or individual titles?\n",
      "\t<other> Either lol.. I love comedies, but horror movies terrify me. <self> I can't watch horror movies. I am up all night. My kids however love them.\n",
      "\t<other> Isnt that funny! I have to watch cartoons after anything scary. <self> I just cant watch them in general. For some reason my mind just goes into overdrive.\n",
      "\t<other> How old are your kid?. <self> 15. Do you have any?\n",
      "Summary: \n",
      "\tI have kids.\n",
      "\tMy cousin recently got married at the beach.\n",
      "\tI do not like horror movies.\n",
      "\tMy kids love horror movies.\n",
      "\tHorror movies makes my mind go into overdrive.\n",
      "Prediction: \n",
      "\tI have kids.\n",
      "\tI have a cousin who got married.\n",
      "\t<nofact>\n",
      "\t<nofact>\n",
      "\tI am scared of horror movies. I have kids.\n",
      "\t<nofact>\n",
      "\tI have a 15-year-old son.\n",
      "\n",
      "2023-05-18 23:44:11,788 SPAM     | Generate: pred_fact=tensor([False, False, False,  True,  True,  True,  True])\n",
      "2023-05-18 23:44:11,790 SPAM     | Generate: gen_out=tensor([[    2,     0,     0,     0, 50267,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    2,     0,     0,     0,   100,   524,    10, 23298,     4,    38,\n",
      "            33,    10,   422,    11,    19,     5,   488,     4,     2,     1,\n",
      "             1],\n",
      "        [    2,     0,     0,     0,   100,    33,    10,   512,     4,    38,\n",
      "           524,  6549,    62,    13,    41,  7694,   108,  4536,  5191,     4,\n",
      "             2],\n",
      "        [    2,     0,     0,     0,   100,   101,     7,   213,     7,     5,\n",
      "         14193,     4,    38,   101,     7,  3598,    11,    41,   935,  4293,\n",
      "             2],\n",
      "        [    2,     0,     0,     0,   100,   657,     5, 13384,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1]])\n",
      "Utterances: \n",
      "\t<other> Hi there! What’s going on? <self> Just finished wrangling some gators today, you?\n",
      "\t<other> Nothing that exciting! Chilling at home in my favorite sweatsuit. <self> After awhile it almost feels like a normal job, what do you do?\n",
      "\t<other> Eyewear designer. Been wearing them since I was a skinny little redhead boy. <self> Sounds nice, what do you do for fun?.\n",
      "\t<other> Go shopping and lee up on current events. What do you do for work? <self> Gator hunter, not many places will take me after my run in with the law.\n",
      "\t<other> Everyone deserves a second chance! Do you like to travel? <self> Yeah, love cars and car trips, saving up for a 81'camaro. You?\n",
      "\t<other> Sweet ride! Travel would be great but it’s tough to get away from work. Favorite vacation spot? <self> Anywhere quiet, not a fan of cities. Sometimes I'll take my air boat to a swamp..\n",
      "\t<other> Sounds awesome, I need to get away and enjoy all that nature has to offer. <self> I'm the same way, love the outdoors.\n",
      "Summary: \n",
      "\tI have been in trouble with the law, which makes it difficult for me to find work.\n",
      "\tI work as a gator hunter.\n",
      "\tI love cars.\n",
      "\tI'm saving to buy a 1981 Camaro.\n",
      "\tI love road trips.\n",
      "\tI own an air boat, which I ride on swamps.\n",
      "\tI don't like cities.\n",
      "\tI love the outdoors.\n",
      "Prediction: \n",
      "\t<nofact>\n",
      "\t<nofact>\n",
      "\t<nofact>\n",
      "\tI am a hunter. I have a run in with the law.\n",
      "\tI have a car. I am saving up for an 81' Camaro.\n",
      "\tI like to go to the woods. I like to fly in an air boat\n",
      "\tI love the outdoors.\n",
      "\n",
      "2023-05-18 23:44:17,042 SPAM     | Generate: pred_fact=tensor([ True,  True,  True,  True,  True, False, False])\n",
      "2023-05-18 23:44:17,044 SPAM     | Generate: gen_out=tensor([[    2,     0,     0,     0,   100,   524,    31,     5,  1084, 10823,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    2,     0,     0,     0,   100,    33,    57,    10, 26565,    13,\n",
      "           501,   107,     4,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    2,     0,     0,     0,   100,    33,   103,   418,     4,    38,\n",
      "           101,  1637,     4,    38,    33,   103,     4,    38,  1930,    24,\n",
      "             2],\n",
      "        [    2,     0,     0,     0,   100,    33,    10,  9544,  2761,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    2,     0,     0,     0,   100,   101,  4133,     4,    38,    33,\n",
      "            10,  1141,     4,    38,   101,  4133,    10,   319,     4,     2,\n",
      "             1],\n",
      "        [    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1]])\n",
      "Utterances: \n",
      "\t<other> Hey is english your mother tongue? <self> It is. I'm from the midwest.\n",
      "\t<other> Oh. I teach english so I was gonna do a shameless plug. <self> Lol. I've been a dentist for the past 14 years.\n",
      "\t<other> You must have money. I volunteer with the homeless. You should open your wallet. <self> I have some, but I spend it on gold which is my favorite metal.\n",
      "\t<other> Fair enough. But you should really consider being charitable. <self> I actually help out my twin sister quite a bit.\n",
      "\t<other> But that is family doesn't count. Do you like movies? <self> Love movies. I watch them a lot as my wife and I sleep in different rooms.\n",
      "\t<other> Wow, unecessarily deep. Maybe we should go see a comedy together? <self> That sounds fun. What do you have in mind?\n",
      "\t<other> Maybe something madea related.. <self> I'm not familiar with that.\n",
      "Summary: \n",
      "\tEnglish is my mother tongue.\n",
      "\tI am from the Midwest.\n",
      "\tI have been a dentist for the past 14 years.\n",
      "\tI spend money on gold, which is my favorite metal.\n",
      "\tI help my twin sister a lot.\n",
      "\tI love watching movies.\n",
      "\tMy wife sleeps in a different room than me.\n",
      "\tI have not seen a Madea movie.\n",
      "Prediction: \n",
      "\tI am from the midwest.\n",
      "\tI have been a dentist for 14 years.\n",
      "\tI have some money. I like gold. I have some. I spend it\n",
      "\tI have a twin sister.\n",
      "\tI like movies. I have a wife. I like movies a lot.\n",
      "\t<nofact>\n",
      "\t<nofact>\n",
      "\n",
      "2023-05-18 23:44:20,785 SPAM     | Generate: pred_fact=tensor([False,  True,  True,  True,  True, False])\n",
      "2023-05-18 23:44:20,787 SPAM     | Generate: gen_out=tensor([[    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,   173,    13,  2185,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,   101,     7,  6345,     8,  1045,\n",
      "           930,     4,     2,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,   524,   765,     4,    38,   218,\n",
      "            75,    33,   203,  6958,     4,     2],\n",
      "        [    2,     0,     0,     0,   100,   697,    11,  2240,     4,    38,\n",
      "           657,   961,     4,     2,     1,     1],\n",
      "        [    2,     0,     0,     0, 50267,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1]])\n",
      "Utterances: \n",
      "\t<other> Hello stranger! I hope you are ready to get to know me. <self> Hello! What do you do for a living?\n",
      "\t<other> I enjoy to work outside, mainly landscaping and such. You? <self> I can't handle having a boss, so I work for myself.\n",
      "\t<other> I enjoy working by myself as well. Do you have any hobbies? <self> Yes, mainly the arts. Painting and creating music! You?\n",
      "\t<other> Although my short stature might deceive you, I enjoy playing basketball. <self> Same here, and I also do not have much height to me!\n",
      "\t<other> Short people unite! Where are you from? <self> Virginia. I love it here and I love everyone! You?\n",
      "\t<other> My mom is originally from canada so I stayed in the area. It gets rather cold. <self> The weather in virginia is insane. Snow one day, hot the next.\n",
      "Summary: \n",
      "\tI am self employed.\n",
      "\tI am a painter.\n",
      "\tI write and play music.\n",
      "\tI am a short person.\n",
      "\tI am from Virginia.\n",
      "\tI love Virginia.\n",
      "\tI don't think the weather in Virginia is very nice.\n",
      "Prediction: \n",
      "\t<nofact>\n",
      "\tI work for myself.\n",
      "\tI like to paint and create music.\n",
      "\tI am short. I don't have much height.\n",
      "\tI live in Virginia. I love everyone.\n",
      "\t<nofact>\n",
      "\n",
      "2023-05-18 23:44:24,937 SPAM     | Generate: pred_fact=tensor([ True,  True, False, False, False, False])\n",
      "2023-05-18 23:44:24,938 SPAM     | Generate: gen_out=tensor([[    2,     0,     0,     0,   100, 11822,   127,  9927,    10,   319,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,   236,     7,    28,    10,  9008,\n",
      "             4,    38,   236,     7,   213,     7,   334,     4,     2],\n",
      "        [    2,     0,     0,     0, 50267,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1]])\n",
      "Utterances: \n",
      "\t<other> Hello there, I hope you've brushed your teeth this morning. <self> I brush my teeth a lot. I brought my teeth in my backpack today.\n",
      "\t<other> That's great, in my 14 year as a dentist I hate when people forget them. <self> I am hoping to do omething imilar, I wanna be a nurse.\n",
      "\t<other> There is high demand for nurses in the midwest where I live. <self> Great but I don't want to relocate no vegans there only cows.\n",
      "\t<other> My life isn't great here, my wife won't even sleep in the same room as me. <self> Sounds terrible get a divorce.\n",
      "\t<other> Well, then I would have to give back my gold wedding ring, and gold is my favorite. <self> Did you ever see the movie goldmember?\n",
      "\t<other> No, but my twin sister did. She raves about it constantly. <self> You should see it you'd like it if you like gold.\n",
      "Summary: \n",
      "\tI brush my teeth a lot.\n",
      "\tMy teeth are in my backpack.\n",
      "\tI want to be a nurse.\n",
      "\tI am vegan.\n",
      "\tI have seen the movie Goldmember.\n",
      "Prediction: \n",
      "\tI brush my teeth a lot.\n",
      "\tI want to be a nurse. I want to go to school.\n",
      "\t<nofact>\n",
      "\t<nofact>\n",
      "\t<nofact>\n",
      "\t<nofact>\n",
      "\n",
      "2023-05-18 23:44:28,563 SPAM     | Generate: pred_fact=tensor([False,  True,  True,  True, False, False])\n",
      "2023-05-18 23:44:28,564 SPAM     | Generate: gen_out=tensor([[    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,    33,    10,  3380,     4,    38,\n",
      "            33,  3678,     4,     2,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,   173,    19,  7796,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,    33,   130,  1159,     4,    38,\n",
      "           697,    15,    10,  3380,     4,     2],\n",
      "        [    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0, 50267,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1]])\n",
      "Utterances: \n",
      "\t<other> Salutations! <self> Hey! Do you like animals?\n",
      "\t<other> I have a few dogs and love spending time with them. <self> Nice! I love dogs and hanging out with them on my farm.\n",
      "\t<other> I love coffee, im kind of a connoisseur, know any good methods of brewing? <self> I'll have to look some up, I work with computers.\n",
      "\t<other> I prefer my leisure activities, hiking camping and such. <self> I do those on the farm with my three kids.\n",
      "\t<other> I also enjoy bowling in a bathrobe and drinking white russians... <self> Nice! Maybe I'll see if that's possible on the farm.\n",
      "\t<other> Sounds good. Any other activities? <self> Playing with the dogs, working on computers in the fields.\n",
      "Summary: \n",
      "\tI have a farm.\n",
      "\tI like dogs.\n",
      "\tMy work involves computers.\n",
      "\tI have three kids.\n",
      "Prediction: \n",
      "\t<nofact>\n",
      "\tI have a farm. I have dogs.\n",
      "\tI work with computers.\n",
      "\tI have three kids. I live on a farm.\n",
      "\t<nofact>\n",
      "\t<nofact>\n",
      "\n",
      "2023-05-18 23:44:32,834 SPAM     | Generate: pred_fact=tensor([False,  True,  True, False,  True, False])\n",
      "2023-05-18 23:44:32,836 SPAM     | Generate: gen_out=tensor([[    2,     0,     0,     0, 50267,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,   697,    11,  7227,     4,    38,\n",
      "           524,  1884,     7,  7865,     7,     5,  4105,  1010,     4,     2],\n",
      "        [    2,     0,     0,     0,   100,    33,    10,  2793,   512,     4,\n",
      "            38,   101,  3403,     4,     2,     1,     1,     1,     1,     1],\n",
      "        [    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,   524,    10, 12953,     8,  2440,\n",
      "             4,  1308,  1041,    58,    11,    10, 12308,     4,     2,     1],\n",
      "        [    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]])\n",
      "Utterances: \n",
      "\t<other> Hi there! Nice day to to fishing, would you say? <self> It sure is, the alaskan salmon are spawning now I think.\n",
      "\t<other> Are you from alaska? Where you from? <self> I lived there for three years, im hopin to retire to the beach soon.\n",
      "\t<other> Yah, trying to decide on fishing or baseball. What do you like. <self> Well I srive a smart car so baseball would be my choice.\n",
      "\t<other> Want to race? I have a truck. Haha! <self> Sounds like a sure thing! Lol waht color hair and eyes do you have?\n",
      "\t<other> Brown and brown again.. <self> Blonde and blue here. My folks lived up north and started a cult.\n",
      "\t<other> Wow! I'm from new england. That is pretty repulsive to me! <self> Its a cult of personality though!\n",
      "Summary: \n",
      "\tI live in alaska for 3 years.\n",
      "\tI drive a smart car.\n",
      "\tI have blonde eyes and blue hair.\n",
      "\tMy parents are from the north.\n",
      "Prediction: \n",
      "\t<nofact>\n",
      "\tI live in Alaska. I am planning to retire to the beach soon.\n",
      "\tI have a smart car. I like baseball.\n",
      "\t<nofact>\n",
      "\tI am a blonde and blue. My parents were in a cult.\n",
      "\t<nofact>\n",
      "\n",
      "2023-05-18 23:44:37,038 SPAM     | Generate: pred_fact=tensor([ True,  True, False, False, False, False,  True])\n",
      "2023-05-18 23:44:37,039 SPAM     | Generate: gen_out=tensor([[    2,     0,     0,     0,   100,   657,     7,  3539,     4,    38,\n",
      "           697,   583,     5,  6444,     4,     2],\n",
      "        [    2,     0,     0,     0,   100,   173,    23,    10,  3299,    18,\n",
      "           558,     4,     2,     1,     1,     1],\n",
      "        [    2,     0,     0,     0, 50267,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,   524,  1099,    23, 10638,     4,\n",
      "            38,   101,  5651,     4,     2,     1]])\n",
      "Utterances: \n",
      "\t<other> Hey I'm frank. I grew up in ca on the beach. What about you? <self> Hi! I love to fish and spend as much time as possible near the ocean.\n",
      "\t<other> Thats awesome! My dad owns a surf shop. Morning surfing is my favorite. <self> I don't have time to surf anymore since I work at a doctor's office.\n",
      "\t<other> That's a good career though. I'm in a band. I play the drums and write music.. <self> Right now I am listening to sublime a lot when I relax on the beach.\n",
      "\t<other> I love them! I would love to see them live one day. <self> Do you go to a lot of concerts?\n",
      "\t<other> Not other than the ones I play in. <self> How many people are in your band?\n",
      "\t<other> 4. The singer is my best friend. I write the songs and he sings them. <self> Neat. You must have been a good student at writing.\n",
      "\t<other> That was the only subject I was good in!. <self> I understand! I was bad at math. I preferred fishing.\n",
      "Summary: \n",
      "\tI love to fish.\n",
      "\tI love the ocean.\n",
      "\tI am to busy to surf.\n",
      "\tI work at a doctor's office.\n",
      "\tI relax on the beach.\n",
      "\tI listen to sublime.\n",
      "\tI was bad at math in school.\n",
      "Prediction: \n",
      "\tI love to fish. I live near the ocean.\n",
      "\tI work at a doctor's office.\n",
      "\t<nofact>\n",
      "\t<nofact>\n",
      "\t<nofact>\n",
      "\t<nofact>\n",
      "\tI am bad at math. I like fishing.\n",
      "\n",
      "2023-05-18 23:44:37,040 VERBOSE  | Evaluated 10/20 samples\n",
      "2023-05-18 23:44:40,890 SPAM     | Generate: pred_fact=tensor([ True,  True,  True,  True, False,  True])\n",
      "2023-05-18 23:44:40,891 SPAM     | Generate: gen_out=tensor([[    2,     0,     0,     0,   100,   173,    23,   173,     4,    38,\n",
      "           657,  5919,     4,     2,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,    33,    80,  7172,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,   173,    11,    10,   633,     4,\n",
      "            38,   524,    10, 11342,  7037,     4,     2],\n",
      "        [    2,     0,     0,     0,   100,    33,    10,   284,     4,    38,\n",
      "           524,  1375,     4,     2,     1,     1,     1],\n",
      "        [    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,   697,    11,  1261,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1]])\n",
      "Utterances: \n",
      "\t<other> Hello, just finished up my tennis lesson. <self> Cool love tennis I am at work bored to death.\n",
      "\t<other> Darn, I stay at home with my twin daughters.. <self> I have two daughters to 5 years old and 3 months.\n",
      "\t<other> Cute! Do you have any free time? <self> Barely between my regular career and turking it is hard lately I have been cutting back.\n",
      "\t<other> I hear ya, I only have time for tennis and church on sundays. <self> I do have time for church but I have been moving lately family life is hard.\n",
      "\t<other> My husband is gone every other week for work, its rough. <self> Really that sounds hard I feel for you but it will get better overtime.\n",
      "\t<other> I hope so, my family lives in sweden, so I can be lonely. <self> Wow that is very far we stay in florida sunny weather.\n",
      "Summary: \n",
      "\tI like tennis.\n",
      "\tMy work makes me bored.\n",
      "\tMy daughters are 5 years old and 3 months old.\n",
      "\tI have two daughters.\n",
      "\tI have a career and do side work.\n",
      "\tI do not have much free time.\n",
      "\tMy family life is hard.\n",
      "\tI go to church.\n",
      "\tI am currently moving.\n",
      "\tI like the sunny weather.\n",
      "\tI live in Florida.\n",
      "Prediction: \n",
      "\tI work at work. I love tennis.\n",
      "\tI have two daughters.\n",
      "\tI work in a job. I am a turking.\n",
      "\tI have a family. I am moving.\n",
      "\t<nofact>\n",
      "\tI live in Florida.\n",
      "\n",
      "2023-05-18 23:44:45,741 SPAM     | Generate: pred_fact=tensor([ True, False,  True,  True,  True, False])\n",
      "2023-05-18 23:44:45,743 SPAM     | Generate: gen_out=tensor([[    2,     0,     0,     0,   100,   524,    11,    10,  2303,     4,\n",
      "            38,   524,    11,     5,   121,     4,   104,     4,    13,   173,\n",
      "             2],\n",
      "        [    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    2,     0,     0,     0,   100,    33,    10,  1141,     8,  1159,\n",
      "             4,    38,  1504,    10,   319,    13,   173,     4,     2,     1,\n",
      "             1],\n",
      "        [    2,     0,     0,     0,   100,   524,    10, 28783,    50, 13384,\n",
      "          1907,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    2,     0,     0,     0,   100,   524,    31,   764,  2659,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    2,     0,     0,     0, 50267,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1]])\n",
      "Utterances: \n",
      "\t<other> Hi! I just finished a run. How are you? <self> Pretty good, I just arrive at my hotel on work travel. Where are you from?\n",
      "\t<other> Originally, venice beach. Though I have been all over. 20 countries! <self> Wow. That is a lot of travel. Do you enjoy traveling?\n",
      "\t<other> Hate it, but love running. Lose track of where I am. <self> I travel a lot for work. I don't mind it, but miss my wife and kids.\n",
      "\t<other> I picked up a yodel in my travels that might help you from missing them. <self> I'm more of a fisherman or outdoors type.\n",
      "\t<other> Sorry, I just love singing. Get it from my parents. They met in high school choir. <self> Did they meet in venice? I'm from san francisco.\n",
      "\t<other> Yes. San francisco! Does it have my favorite turquoise oceans? <self> Yes, beautiful water. And some of the best restaurants.\n",
      "Summary: \n",
      "\tI just arrived at my hotel.\n",
      "\tI travel for work.\n",
      "\tI travel a lot for work.\n",
      "\tI miss my wife and kids.\n",
      "\tI am a fisherman or outdoors type of person.\n",
      "\tI'm from San Francisco.\n",
      "\tSan Francisco has beautiful water and the best restaurants.\n",
      "Prediction: \n",
      "\tI am in a hotel. I am in the U.S. for work\n",
      "\t<nofact>\n",
      "\tI have a wife and kids. I travel a lot for work.\n",
      "\tI am a fisherman or outdoors type.\n",
      "\tI am from San Francisco.\n",
      "\t<nofact>\n",
      "\n",
      "2023-05-18 23:44:49,279 SPAM     | Generate: pred_fact=tensor([True, True, True, True, True, True])\n",
      "2023-05-18 23:44:49,280 SPAM     | Generate: gen_out=tensor([[   2,    0,    0,    0,  100,  524,  974,  107,  793,    4,    2,    1,\n",
      "            1,    1,    1,    1,    1,    1],\n",
      "        [   2,    0,    0,    0,  100,  657, 1531,    4, 1308, 4252, 1665,   11,\n",
      "            5, 3835,    4,    2,    1,    1],\n",
      "        [   2,    0,    0,    0,  100,   33,   10,  657,   13, 2600,    4,   38,\n",
      "           33, 1410,   10,  319,    4,    2],\n",
      "        [   2,    0,    0,    0,  100,  657, 7548, 2480, 6353,    4,   38,  657,\n",
      "         8087,    4,    2,    1,    1,    1],\n",
      "        [   2,    0,    0,    0,  100,  173,   23,   10,  650,  265,    4,    2,\n",
      "            1,    1,    1,    1,    1,    1],\n",
      "        [   2,    0,    0,    0,  100,  240,   10,   92,  790,    4,    2,    1,\n",
      "            1,    1,    1,    1,    1,    1]])\n",
      "Utterances: \n",
      "\t<other> Hi, my name is cat. <self> Hi cat! How are you? I'm 27.\n",
      "\t<other> I am very old, I have lots of brothers and sisters, over 11. <self> I love fun! My dad served in the army.\n",
      "\t<other> I know a few people who are related to army people. <self> We moved around a lot which wasn't fun but I developed a love for reading.\n",
      "\t<other> I like horses and always spend time with them to relax. <self> I love horses. Do you ride? I love chocolate ice cream, thats how I relax :).\n",
      "\t<other> Yes I ride on the beach near me. <self> Oh nice! The small business I work for doesn't let me get to the beach much.\n",
      "\t<other> That is mean. I want to have a new house so saving up now. <self> I need a new house too but it'll take me awhile.\n",
      "Summary: \n",
      "\tI am 27 years old.\n",
      "\tI have a dad who served in the army.\n",
      "\tI love reading.\n",
      "\tI like chocolate ice cream.\n",
      "\tI like horses.\n",
      "\tI don't spend a lot of time at the beach.\n",
      "\tI work for a small business.\n",
      "\tI would like to get a new house.\n",
      "Prediction: \n",
      "\tI am 27 years old.\n",
      "\tI love fun. My dad served in the army.\n",
      "\tI have a love for reading. I have moved a lot.\n",
      "\tI love chocolate ice cream. I love horses.\n",
      "\tI work at a small business.\n",
      "\tI need a new house.\n",
      "\n",
      "2023-05-18 23:44:52,751 SPAM     | Generate: pred_fact=tensor([True, True, True, True, True, True, True])\n",
      "2023-05-18 23:44:52,753 SPAM     | Generate: gen_out=tensor([[    2,     0,     0,     0,   100,    33,  1159,     4,    38,   697,\n",
      "            11,    10,   430,   194,     4,     2],\n",
      "        [    2,     0,     0,     0,   100,    33,    10,  2335,  1386,     9,\n",
      "          1159,     4,     2,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,  1504,    13,  1612,     4,    38,\n",
      "          1994,  1859,     4,     2,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,   101,     7,  6345,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,    33,    10,  2335,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,   310, 21072,     4,    38,  4076,\n",
      "          3895,     4,     2,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,   101,   909,  3895,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1]])\n",
      "Utterances: \n",
      "\t<other> Hey do you like kids? <self> Hey love them but always seeing them where I live.\n",
      "\t<other> I actually have kids... All of which are younger than 9! It is tough! <self> I'm sure! I have my dog instead of kids.\n",
      "\t<other> Do you speak any german? <self> Yes, I travel for my sports so I have to know some german..\n",
      "\t<other> Do you know how to say \"grown up\" in german? Tell me. <self> I wish! I like to paint instead of know that kinda stuff.\n",
      "\t<other> You could always google it for me and let me know ;). Do you like instruments? <self> Kinda. My dog barks when I play.\n",
      "\t<other> You play too? What do you play? <self> I play drums with my paintburshes and drink coffee.\n",
      "\t<other> Coffee is addicting. I like iced cappucinos. I play the flute. <self> Nice!i like a black coffee.\n",
      "Summary: \n",
      "\tI love kids.\n",
      "\tI have a dog.\n",
      "\tI speak German.\n",
      "\tI like to paint.\n",
      "\tI play instruments.\n",
      "\tI play drums.\n",
      "\tI drink coffee.\n",
      "\tI like black coffee.\n",
      "Prediction: \n",
      "\tI have kids. I live in a different state.\n",
      "\tI have a dog instead of kids.\n",
      "\tI travel for sports. I speak German.\n",
      "\tI like to paint.\n",
      "\tI have a dog.\n",
      "\tI play drums. I drink coffee.\n",
      "\tI like black coffee.\n",
      "\n",
      "2023-05-18 23:44:55,726 SPAM     | Generate: pred_fact=tensor([ True,  True,  True,  True,  True, False])\n",
      "2023-05-18 23:44:55,728 SPAM     | Generate: gen_out=tensor([[    2,     0,     0,     0,   100,   393,  1323,  1123,    11,   285,\n",
      "             4,     2,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,  2649,   334,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,   524,    41, 40701,     9,    10,\n",
      "          2366,   997,   937,     4,     2],\n",
      "        [    2,     0,     0,     0,   100,   101,  8087,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,   308,   132,  8087,     4,     2,\n",
      "             1,     1,     1,     1,     1],\n",
      "        [    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1]])\n",
      "Utterances: \n",
      "\t<other> Hi. I'm a student at fsu. Going for my degree in marketing. <self> Well before we get started I wanna let you know.. I never pass gas in public. Sorry if thats tmi.\n",
      "\t<other> Respectful! I'm in school on a baseball scholarship. <self> Haha I know right! Aw man I miss school! That is awesome tho!\n",
      "\t<other> I really like it. I'm also taking spanish and french. <self> Well.. I am a ancestor of a civil war general do you study this in school??\n",
      "\t<other> Cool. I'd like to be an ad designer when I graduate. <self> That is amazing goals. Do you like horses? I am crazy about them.\n",
      "\t<other> Love horses. Do you own a horse? <self> I do. I own 2 at the moment. Would love more in the future.\n",
      "\t<other> I'm originally from kentucky. Beautiful horse farms there. <self> Wow I would love to go there some day.\n",
      "Summary: \n",
      "\tI never pass gas in public.\n",
      "\tI miss school.\n",
      "\tOne of my ancestors is a civil war general.\n",
      "\tI love horses.\n",
      "\tI own 2 horses and want more.\n",
      "\tI'd like to go to Kentucky someday.\n",
      "Prediction: \n",
      "\tI never pass gas in public.\n",
      "\tI miss school.\n",
      "\tI am an ancestor of a civil war general.\n",
      "\tI like horses.\n",
      "\tI own 2 horses.\n",
      "\t<nofact>\n",
      "\n",
      "2023-05-18 23:45:00,259 SPAM     | Generate: pred_fact=tensor([ True,  True,  True,  True,  True, False,  True])\n",
      "2023-05-18 23:45:00,261 SPAM     | Generate: gen_out=tensor([[    2,     0,     0,     0,   100,   697,    11,  8688,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    2,     0,     0,     0,   100,    33,    80,  7502,     8,    10,\n",
      "          9544,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    2,     0,     0,     0,   100,   524,    10, 26565,     4,    38,\n",
      "            33,    57,   447,    25,    10, 26565,    13,   501,   107,     4,\n",
      "             2],\n",
      "        [    2,     0,     0,     0,   100,   682,   300, 18264,     4,    38,\n",
      "           524, 18264,     4,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    2,     0,     0,     0,   100,   101,  1637,     4,    38,   524,\n",
      "            45,    88,  1612,     4,    38,   101, 10340,     4,     2,     1,\n",
      "             1],\n",
      "        [    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    2,     0,     0,     0,   100,   657,  1111,   689,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1]])\n",
      "Utterances: \n",
      "\t<other> Hi, I live in india when I was young. How about you.. <self> I live in nebraska.\n",
      "\t<other> Okay. My family move to usa. So far I like live here.. <self> Thats nice. I have two sisters and im a twin.\n",
      "\t<other> That is cool to be a twin. Did you go to college I did. <self> Yeah I went to dentist school. Ive been working as one for fourteen years.\n",
      "\t<other> Great. I want for business, I got my master degree in business. <self> I recently got divorce. My wife and I dont even sleep together anymore.\n",
      "\t<other> That sad. I play tennis, what sport you play.. <self> Not really into any sports. Ive been big into metals my fave is gold.\n",
      "\t<other> I love different culture food and cook it.. <self> What kind of food do you like to cook?\n",
      "\t<other> India, chinese and american food. <self> I love chinese food too!\n",
      "Summary: \n",
      "\tI currently live in Nebraska.\n",
      "\tI have two sisters, and one of them is my twin.\n",
      "\tI went to dentist school, and have been working as a dentist for fourteen years.\n",
      "\tI have gotten divorced from my wife.\n",
      "\tI like metals, my favorite one is gold.\n",
      "\tI love Chinese Food.\n",
      "Prediction: \n",
      "\tI live in Nebraska.\n",
      "\tI have two sisters and a twin.\n",
      "\tI am a dentist. I have been working as a dentist for 14 years.\n",
      "\tI recently got divorced. I am divorced.\n",
      "\tI like gold. I am not into sports. I like metals.\n",
      "\t<nofact>\n",
      "\tI love Chinese food.\n",
      "\n",
      "2023-05-18 23:45:04,332 SPAM     | Generate: pred_fact=tensor([ True,  True,  True,  True,  True, False])\n",
      "2023-05-18 23:45:04,333 SPAM     | Generate: gen_out=tensor([[    2,     0,     0,     0,   100,  2307,    62,    11,     5,   343,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    2,     0,     0,     0,   100,    33,    10,  4758,     4,    38,\n",
      "            33,    10, 35292,     4,    38,   657,  1782,  3122,    23,     5,\n",
      "             2],\n",
      "        [    2,     0,     0,     0,   100,   101,     7,  4076,    38,  7618,\n",
      "          6845,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    2,     0,     0,     0,   100,    33,   682, 39744,   127,  2549,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    2,     0,     0,     0,   100,    33,    10,  4758,     4,    38,\n",
      "            33,    10, 35292,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1]])\n",
      "Utterances: \n",
      "\t<other> Hello! I am country girl living in the big city. Where are you from? <self> I grew up completely different, in the city. Where do you like to visit?\n",
      "\t<other> I have one dog and enjoy visiting dog parks with him cross-country. <self> My cat just gave birth to a kitten. I love seeing animals at the zoo.\n",
      "\t<other> I'm very athletic and run when I'm not having my favorite drink, which is coffee. <self> Iced tea is what I prefer to drink. Have you done anything fun recently?\n",
      "\t<other> I am a local artist and recenlt held a major drawing con. <self> Interesting! I just colored my hair, as well as got it cut.\n",
      "\t<other> Cool! What's a fun fact about yourself? <self> I have one pet, a cat. She goes with me everywhere, along with her kitten.\n",
      "\t<other> Oh okay, I just have my dog. My best friend. <self> Best friends are good. Where is a place you like to visit?\n",
      "Summary: \n",
      "\tI grew up in the city.\n",
      "\tI have a cat who just had kittens.\n",
      "\tI like going to the zoo.\n",
      "\tI like iced tea.\n",
      "\tI just cut and colored my hair.\n",
      "Prediction: \n",
      "\tI grew up in the city.\n",
      "\tI have a cat. I have a kitten. I love seeing animals at the\n",
      "\tI like to drink Iced tea.\n",
      "\tI have recently dyed my hair.\n",
      "\tI have a cat. I have a kitten.\n",
      "\t<nofact>\n",
      "\n",
      "2023-05-18 23:45:06,141 SPAM     | Generate: pred_fact=tensor([False, False, False, False, False, False, False])\n",
      "2023-05-18 23:45:06,142 SPAM     | Generate: gen_out=tensor([[    2,     0, 50267,     2,     1,     1],\n",
      "        [    2,     0,     0,     0, 50267,     2],\n",
      "        [    2,     0, 50267,     2,     1,     1],\n",
      "        [    2,     0, 50267,     2,     1,     1],\n",
      "        [    2,     0,     0,     0, 50267,     2],\n",
      "        [    2,     0,     0,     0, 50267,     2],\n",
      "        [    2,     0, 50267,     2,     1,     1]])\n",
      "Utterances: \n",
      "\t<other> Hi! How are you? <self> Tired. Just finished the last of the boxes. How are you?.\n",
      "\t<other> I'm tired too. Too much focusing on sheet music. Gives me a headache. You moving? <self> Yeah. Chasing a job two states over. What kind of music are you working on?.\n",
      "\t<other> Concert band. Marching band season's over right now. <self> Sounds tense. Maybe we both need a vacation..\n",
      "\t<other> I usually go on vacation with my parents in the summer, when they are off. <self> Oh yeah? Where do you end up going?.\n",
      "\t<other> Wherever mom and dad decide. You have a favorite place to visit? <self> Know how that is, my brothers always dictated the travel terms. London's nice though.\n",
      "\t<other> I'd love to go to england to see all of dickens'settings, and austen's, and the brontes '... <self> Bring proper shoes, then. Galoshes, even. My sneakers never held up to the rain that well..\n",
      "\t<other> Especially if I'm slogging through the moors, right? I do wear sneakers a lot though. <self> Right. Mmfgh.. Now I have to think of what to make for dinner tonight. Suggestions?.\n",
      "Summary: \n",
      "\tI am tired from packing.\n",
      "\tI am moving to another state.\n",
      "\tI have brothers.\n",
      "\tI like London.\n",
      "\tI visited England.\n",
      "\tI cook.\n",
      "Prediction: \n",
      "\t<nofact>\n",
      "\t<nofact>\n",
      "\t<nofact>\n",
      "\t<nofact>\n",
      "\t<nofact>\n",
      "\t<nofact>\n",
      "\t<nofact>\n",
      "\n",
      "2023-05-18 23:45:10,421 SPAM     | Generate: pred_fact=tensor([True, True, True, True, True, True, True])\n",
      "2023-05-18 23:45:10,423 SPAM     | Generate: gen_out=tensor([[    2,     0,     0,     0,   100,    33,    10,  2138,  1440, 22401,\n",
      "             4,    38,   101,     7,   310,   569,   426,     4,     2],\n",
      "        [    2,     0,     0,     0,   100,   657,  3678,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,   101,     7,  2792,    23,  2700,\n",
      "          4228,     4,     2,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,   697,    11,  1261,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,    33,    10,  2761,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,   101,   726, 31732,     4,    38,\n",
      "           524,    10,   828,     9,    10, 39547,     4,     2,     1],\n",
      "        [    2,     0,     0,     0,   100,   101,  9366,     8,   569,   426,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1]])\n",
      "Utterances: \n",
      "\t<other> Good morning to ya!! My name is jason. <self> Ugh too early.. Was up late gaming last night! Names bob.\n",
      "\t<other> Just got back from walking my german shepherds snickers and bounty. <self> Oh I love dogs. Do you work today?\n",
      "\t<other> I will go in much later. How about you? <self> Shift at best buy tonight. Love the discount though.\n",
      "\t<other> Oh cool!! Where are you from? Navy brat here, schooled in spain and france. <self> Oh wow. From florida, still here too, nice and warm!\n",
      "\t<other> Love florida. Siblings? None for me. Only child. <self> A sister who is also a gamer lol. Do u play league of legends?\n",
      "\t<other> I don't play as much as I used to. But every once in awhile. <self> Alistar is my favorite champion. Im a bit of a nerd lol..\n",
      "\t<other> Ha ha. Think I'll grab burger and fries for lunch in a bit. <self> Oh one of my favorites.. Pizza and video games with friends for me.\n",
      "Summary: \n",
      "\tmy name is bob.\n",
      "\ti play video games.\n",
      "\ti like dogs.\n",
      "\ti work at best buy.\n",
      "\tI am from florida.\n",
      "\tI have a sister.\n",
      "\tI love league of legends.\n",
      "\tI like burgers and fries, pizza.\n",
      "Prediction: \n",
      "\tI have a brother named bob. I like to play video games.\n",
      "\tI love dogs.\n",
      "\tI like to shop at Best Buy.\n",
      "\tI live in Florida.\n",
      "\tI have a sister.\n",
      "\tI like Alistar. I am a bit of a nerd.\n",
      "\tI like pizza and video games.\n",
      "\n",
      "2023-05-18 23:45:13,699 SPAM     | Generate: pred_fact=tensor([False,  True,  True,  True, False, False])\n",
      "2023-05-18 23:45:13,700 SPAM     | Generate: gen_out=tensor([[    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,   657,  3403,     4,    38,    33,\n",
      "            10,   979,     4,     2,     1,     1,     1],\n",
      "        [    2,     0,     0,     0,   100,   218,    75,  3529,  4884,     4,\n",
      "            38,   101, 25475,     8, 23320,     4,     2],\n",
      "        [    2,     0,     0,     0,   100,  1994,  1859,     4,    38,  1994,\n",
      "          1859,  6626,  7240,     4,     2,     1,     1],\n",
      "        [    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0, 50267,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1]])\n",
      "Utterances: \n",
      "\t<other> Hello how are you doing today? <self> Very well thank you. How are you?\n",
      "\t<other> Going to head out soon to play some baseball. I really like the game. <self> I love baseball too. So does my son. We play every chance we get.\n",
      "\t<other> After our game, we plan to head out to a nice seafood restaurant. I love lobster. <self> I do not eat any kinds of meat but my son like lobster and crab.\n",
      "\t<other> Do you speak any other languages? I enjoy learning them. <self> Not fluently. I speak a little bit of german because my mom was born in germany.\n",
      "\t<other> I am currently going to school to get my degree in marketing and talking french at night. <self> Good luck with your degree! French is probably more useful than german:).\n",
      "\t<other> I hope to design ads for local non profit companies. <self> That is a great goal!!! Is it similar to volunteering?\n",
      "Summary: \n",
      "\tI love baseball and so does my son.\n",
      "\tI do not eat meat.\n",
      "\tMy son likes lobster and crab.\n",
      "\tMy mom was born in Germany.\n",
      "\tI speak a little bit of German.\n",
      "Prediction: \n",
      "\t<nofact>\n",
      "\tI love baseball. I have a son.\n",
      "\tI don't eat meat. I like lobster and crab.\n",
      "\tI speak German. I speak German fluently.\n",
      "\t<nofact>\n",
      "\t<nofact>\n",
      "\n",
      "2023-05-18 23:45:13,701 VERBOSE  | Evaluated 20/20 samples\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'t'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m eval_kwargs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mmetrics\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mter\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlog_interval\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m10\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdecoder_max\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m20\u001b[39m}\n\u001b[0;32m----> 2\u001b[0m eval_stats \u001b[39m=\u001b[39m msc_summaries\u001b[39m.\u001b[39;49mevaluate(model, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49meval_kwargs)\n",
      "File \u001b[0;32m~/Programming/PEX/dataset/msc_summary.py:333\u001b[0m, in \u001b[0;36mMSC_Summaries.evaluate\u001b[0;34m(self, model, metrics, nofact_token, device, decoder_max, print_max, log_interval)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[39mif\u001b[39;00m (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m log_interval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    331\u001b[0m         logging\u001b[39m.\u001b[39mverbose(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEvaluated \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m samples\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 333\u001b[0m stats, results_dict \u001b[39m=\u001b[39m calc_stats(pred_summaries, target_summaries, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices, metrics\u001b[39m=\u001b[39;49mmetrics)\n\u001b[1;32m    335\u001b[0m \u001b[39mreturn\u001b[39;00m stats, results_dict\n",
      "File \u001b[0;32m~/Programming/PEX/dataset/msc_summary.py:61\u001b[0m, in \u001b[0;36mcalc_stats\u001b[0;34m(predicted_summaries, target_summaries, indices, metrics)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mterp\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m metrics:\n\u001b[1;32m     59\u001b[0m         metric[\u001b[39m\"\u001b[39m\u001b[39mterp\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mupdate(dialog_nr, \u001b[39m*\u001b[39m\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mcombinations))\n\u001b[0;32m---> 61\u001b[0m all_scores \u001b[39m=\u001b[39m {m: metric[m]\u001b[39m.\u001b[39mcompute() \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m metrics}\n\u001b[1;32m     63\u001b[0m i_start \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     64\u001b[0m \u001b[39mfor\u001b[39;00m dialog_nr \u001b[39min\u001b[39;00m result_dict\u001b[39m.\u001b[39mkeys():\n",
      "File \u001b[0;32m~/Programming/PEX/dataset/msc_summary.py:61\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mterp\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m metrics:\n\u001b[1;32m     59\u001b[0m         metric[\u001b[39m\"\u001b[39m\u001b[39mterp\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mupdate(dialog_nr, \u001b[39m*\u001b[39m\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mcombinations))\n\u001b[0;32m---> 61\u001b[0m all_scores \u001b[39m=\u001b[39m {m: metric[m]\u001b[39m.\u001b[39mcompute() \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m metrics}\n\u001b[1;32m     63\u001b[0m i_start \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     64\u001b[0m \u001b[39mfor\u001b[39;00m dialog_nr \u001b[39min\u001b[39;00m result_dict\u001b[39m.\u001b[39mkeys():\n",
      "\u001b[0;31mKeyError\u001b[0m: 't'"
     ]
    }
   ],
   "source": [
    "eval_kwargs = {'metrics': 'ter', 'device': 'cpu', 'log_interval': 10, 'decoder_max': 20}\n",
    "eval_stats = msc_summaries.evaluate(model, **eval_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    0,   100,   213,    89,     2,     1,     1],\n",
      "        [    0,   100,   213, 50118,  8585,     2,     1],\n",
      "        [    0,   100,   213, 50118,    89,     2,     1],\n",
      "        [    0,   100,   213,  1437, 50118,  8585,     2],\n",
      "        [    0,   100,   213,  1437, 50118,    89,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1]])}\n",
      "['<s>', 'I', 'Ġgo', 'Ġthere', '</s>', '<pad>', '<pad>']\n",
      "['<s>', 'I', 'Ġgo', 'Ċ', 'there', '</s>', '<pad>']\n",
      "['<s>', 'I', 'Ġgo', 'Ċ', 'Ġthere', '</s>', '<pad>']\n",
      "['<s>', 'I', 'Ġgo', 'Ġ', 'Ċ', 'there', '</s>']\n",
      "['<s>', 'I', 'Ġgo', 'Ġ', 'Ċ', 'Ġthere', '</s>']\n"
     ]
    }
   ],
   "source": [
    "s1 = \"I go there\"\n",
    "s2 = \"I go\\nthere\"\n",
    "s3 = \"I go\\n there\"\n",
    "s4 = \"I go \\nthere\"\n",
    "s5 = \"I go \\n there\"\n",
    "encoded_utterances = tokenizer(text=[s1, s2, s3, s4, s5], return_tensors='pt', padding=True)\n",
    "print(encoded_utterances)\n",
    "for enc in encoded_utterances['input_ids']:\n",
    "    print(tokenizer.convert_ids_to_tokens(enc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    0,   100,   213,    89, 50118,  7608,     2,     1,     1,     1,\n",
      "             1],\n",
      "        [    0,   100,   213,    89,  2612,     2,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    0, 50266,   100,   213,    89,  1437, 50265,  7608,     2,     1,\n",
      "             1],\n",
      "        [    0, 50266,   100,   213,    89, 50118, 50265,  7608,     2,     1,\n",
      "             1],\n",
      "        [    0, 50266,   100,   213,    89, 50118, 50265,  2612,     2,     1,\n",
      "             1],\n",
      "        [    0, 50266,    38,   213,    89, 50118,  1437, 50265,  2612,     2,\n",
      "             1],\n",
      "        [    0, 50266,   100,   213,    89,  1437, 50118,  1437, 50265,  2612,\n",
      "             2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "['<s>', 'I', 'Ġgo', 'Ġthere', 'Ċ', 'Why', '</s>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['<s>', 'I', 'Ġgo', 'Ġthere', 'ĠWhy', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['<s>', '<self>', 'I', 'Ġgo', 'Ġthere', 'Ġ', '<other>', 'Why', '</s>', '<pad>', '<pad>']\n",
      "['<s>', '<self>', 'I', 'Ġgo', 'Ġthere', 'Ċ', '<other>', 'Why', '</s>', '<pad>', '<pad>']\n",
      "['<s>', '<self>', 'I', 'Ġgo', 'Ġthere', 'Ċ', '<other>', 'ĠWhy', '</s>', '<pad>', '<pad>']\n",
      "['<s>', '<self>', 'ĠI', 'Ġgo', 'Ġthere', 'Ċ', 'Ġ', '<other>', 'ĠWhy', '</s>', '<pad>']\n",
      "['<s>', '<self>', 'I', 'Ġgo', 'Ġthere', 'Ġ', 'Ċ', 'Ġ', '<other>', 'ĠWhy', '</s>']\n"
     ]
    }
   ],
   "source": [
    "s0 = \"I go there\\nWhy\"\n",
    "s0b = \"I go there Why\"\n",
    "s1 = \"<self>I go there <other>Why\"\n",
    "s2 = \"<self>I go there\\n<other>Why\"\n",
    "s3 = \"<self>I go there\\n<other> Why\"\n",
    "s4 = \"<self> I go there\\n <other> Why\"\n",
    "s5 = \"<self>I go there \\n <other> Why\"\n",
    "encoded_utterances = tokenizer(text=[s0, s0b, s1, s2, s3, s4, s5], return_tensors='pt', padding=True)\n",
    "print(encoded_utterances)\n",
    "for enc in encoded_utterances['input_ids']:\n",
    "    print(tokenizer.convert_ids_to_tokens(enc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<self>I', 'go', 'there', '<other>Why']\n",
      "['<self>I', 'go', 'there', '<other>Why']\n",
      "['<self>I', 'go', 'there', '<other>', 'Why']\n"
     ]
    }
   ],
   "source": [
    "print(s1.split())\n",
    "print(s2.split())\n",
    "print(s5.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 50266,  3945,    47, 15433,    11,     5,   343,    23,    70,\n",
       "            50,   109,    47,   202,   269,  2649,     5,   247,   116,  1437,\n",
       "         50265,    38,   524, 15433,    11,     6,    53,    38,   269,  2649,\n",
       "            24,     4,     2],\n",
       "        [    0, 50266,  3945,    47, 15433,    11,     5,   343,   116,  1437,\n",
       "         50265,   440,     6,    38,   269,  2649,    24,     4,     2,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = \"<self> Are you settling in the city at all or do you still really miss the country? <other> I am settling in, but I really miss it.\"\n",
    "s2 = \"<self> Are you settling in the city? <other> No, I really miss it.\"\n",
    "encoded_utterances = tokenizer(text=[s1, s2], return_tensors='pt', padding=True)\n",
    "encoded_utterances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.cat([encoded_utterances['input_ids'], torch.ones(20, dtype=torch.long).view(2, 10)], dim=1)\n",
    "attn_mask = torch.cat([encoded_utterances['attention_mask'], torch.zeros(20, dtype=torch.long).view(2,10)], dim=1)\n",
    "pred_tokens_2 = model.generate(\n",
    "    input_ids=input_ids.to('cpu'), \n",
    "    # attention_mask=attn_mask.to('cpu'),    # attention_mask is not necessary, is defined within the generatie function\n",
    "    min_length=2,\n",
    "    max_new_tokens=20, \n",
    "    num_beams=1,\n",
    "    do_sample=False,\n",
    "    forced_eos_token_id=list(set([tokenizer.eos_token_id, model.nofact_token_id]))\n",
    ")\n",
    "tokenizer.batch_decode(pred_tokens_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_utterances['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tokens = model.generate(\n",
    "    input_ids=encoded_utterances['input_ids'].to('cpu'), \n",
    "    attention_mask=encoded_utterances['attention_mask'].to('cpu'),\n",
    "    min_length=2,\n",
    "    max_new_tokens=20, \n",
    "    num_beams=1,\n",
    "    do_sample=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.batch_decode(pred_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.bart.config.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = ConditionalFactLoss(nofact_token_id=nofact_token_id, ignore_index=-100, lm_weight=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.randint(0, 100, (2,3,8)).float()\n",
    "t = torch.randint(0,7, (2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion.nllloss(p.permute(0,2,1), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.tensor([[[-6, 0, -5, 7], [-.5, -.5, -8, 0]]]).float()\n",
    "t = torch.tensor([[0, -100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion.nllloss.ignore_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion.nllloss.reduction='mean'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
