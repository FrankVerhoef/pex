{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ.get('OPENAI_KEY')\n",
    "# openai.Model.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " they'll be coming for\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "    engine=\"davinci\", \n",
    "    prompt=\"I expect\", \n",
    "    max_tokens=5\n",
    ")\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=\"Write a tagline for a business called gistai, that specializes in creating personal dialog agents.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
      "  \"id\": \"cmpl-7uJWd2k9pYnRmBLhREDyGJt4ky7lh\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1693655779,\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"\\n\\n\\\"Gistai: Your Conversation Partner for the Digital Age\\\"\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 19,\n",
      "    \"completion_tokens\": 15,\n",
      "    \"total_tokens\": 34\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-7uJWfdur25iyJkm1zYznl9M1gw5Ma\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1693655781,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"The World Series in 2020 was played at Globe Life Field in Arlington, Texas.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 53,\n",
      "    \"completion_tokens\": 18,\n",
      "    \"total_tokens\": 71\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a customer service representative.\"},\n",
    "      {\"role\": \"user\", \"content\": \"Hi, I have a problem with my account.\"}\n",
    "  ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry to hear that. I'll do my best to assist you. Can you please provide me with more details about the issue you're facing?\n"
     ]
    }
   ],
   "source": [
    "reply = response.choices[0][\"message\"][\"content\"]\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-02 13:56:25,558 INFO     | Read 4000 dialogues from MSC session 2 for train dataset\n"
     ]
    }
   ],
   "source": [
    "from dataset.msc_sessions import MSC_Session\n",
    "\n",
    "basedir = \"/Users/FrankVerhoef/Programming/PEX/data/msc/msc_dialogue/\"\n",
    "MSC_Session.set(sessionbreak_token='<sessionbreak>')\n",
    "msc_session = MSC_Session(basedir=basedir, session=2, subset='train', include_history=True, include_persona=True, augmented=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE = {\n",
    "    'sessionbreak': 'system',\n",
    "    'you': 'user',\n",
    "    'me': 'assistant'\n",
    "}\n",
    "OPENAI_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "def get_speaker_mapping(history):\n",
    "\n",
    "    def find(l, x):\n",
    "        i = 0\n",
    "        while i < len(l):\n",
    "            if l[i] == x:\n",
    "                break\n",
    "            i += 1\n",
    "        return i\n",
    "\n",
    "    mapping = {\"Speaker 1\": \"me\", \"Speaker 2\": \"you\", \"Nobody\": \"sessionbreak\"}\n",
    "    speakers = [speaker for speaker, _ in history]\n",
    "\n",
    "    # First check if history contains sessionbreaks\n",
    "    first_sessionbreak = find(speakers, 'Nobody')\n",
    "    if first_sessionbreak >= len(speakers):\n",
    "        persona_sentences = []\n",
    "        dialogue_turns = history\n",
    "        \n",
    "        # No sessionbreaks --> determine mapping based on last speaker_label\n",
    "        if len(speakers) > 0 and speakers[-1] == 'Speaker 1':\n",
    "            mapping = {\"Speaker 1\": \"you\", \"Speaker 2\": \"me\", \"Nobody\": \"sessionbreak\"}\n",
    "\n",
    "    else:\n",
    "        if first_sessionbreak + 1 < len(speakers):\n",
    "\n",
    "            # Now filter out all utterances until the next sessionbreak (because these are persona sentences)\n",
    "            next_sessionbreak = first_sessionbreak + 1 + find(speakers[first_sessionbreak + 1:], 'Nobody')\n",
    "            assert next_sessionbreak < len(speakers), \"Should contain sessionbreak for start of session\"\n",
    "            persona_sentences = history[first_sessionbreak:next_sessionbreak]\n",
    "            dialogue_turns = history[next_sessionbreak:]\n",
    "            speakers = [s for s in speakers[next_sessionbreak:] if s != 'Nobody']\n",
    "\n",
    "            # Update mapping if last speaker is speaker 1\n",
    "            if len(speakers) > 0 and speakers[-1] == 'Speaker 1':\n",
    "                mapping = {\"Speaker 1\": \"you\", \"Speaker 2\": \"me\", \"Nobody\": \"sessionbreak\"}\n",
    "\n",
    "    return mapping, persona_sentences, dialogue_turns\n",
    "\n",
    "def openai_messages(history):\n",
    "\n",
    "    mapping, persona_sentences, dialogue_turns = get_speaker_mapping(history)\n",
    "\n",
    "    messages = []\n",
    "    if len(persona_sentences) > 0:\n",
    "        my_character = [s for p, s in persona_sentences if mapping[p] == 'me']\n",
    "        user_character = [s for p, s in persona_sentences if mapping[p] == 'you']\n",
    "        if len(my_character) > 0:\n",
    "            messages.append({\"role\": \"system\", \"content\": \"I am an assistant with the following persona: \" + ' '.join(my_character)})\n",
    "        else:\n",
    "            messages.append({\"role\": \"system\", \"content\": \"A sessionbreak indicates I have not spoken with the user for a while. If I have chatted with the user before, I use all information that I have about the user to follow up on previous conversations\"})\n",
    "        if len(user_character) > 0:\n",
    "            messages.append({\"role\": \"system\", \"content\": \"The user has the following persona: \" + ' '.join(user_character)})\n",
    "        else:\n",
    "            messages.append({\"role\": \"system\", \"content\": \"I have no information about the user\"})\n",
    "\n",
    "    messages.extend([\n",
    "        {\"role\": ROLE[mapping[speaker]], \"content\": content}\n",
    "        for speaker, content in dialogue_turns\n",
    "    ])\n",
    "    return messages\n",
    "\n",
    "def openai_response(history):\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=openai_messages(history)\n",
    "        )\n",
    "    print(response)\n",
    "    return response.choices[0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Nobody', 'personas'),\n",
       " ('Speaker 1', \"I'm a perfectionist.\"),\n",
       " ('Speaker 1', \"If things aren't done right I'll redo them again and again.\"),\n",
       " ('Speaker 1',\n",
       "  'I take forever to get tasks done so I start early and clock out late.'),\n",
       " ('Speaker 1', 'I work too much.'),\n",
       " ('Speaker 1', 'I think I need a vacation.'),\n",
       " ('Speaker 1',\n",
       "  \"I've been working a lot of extra hours. I want to break from my non-stop work.\"),\n",
       " ('Speaker 1', 'I like going to the beach.'),\n",
       " ('Speaker 1', 'I love brownies.'),\n",
       " ('Speaker 2', \"I served or serve in the military. I've traveled the world.\"),\n",
       " ('Speaker 2', \"I've blown things up.\"),\n",
       " ('Speaker 2', \"I've never been to Bora Bora.\"),\n",
       " ('Speaker 2', 'I love chocolate.'),\n",
       " ('Nobody', '2 days ago'),\n",
       " ('Speaker 1',\n",
       "  'I need some advice on where to go on vacation, have you been anywhere lately?'),\n",
       " ('Speaker 2', \"I have been all over the world. I'm military.\"),\n",
       " ('Speaker 1', 'That is good you have alot of travel experience'),\n",
       " ('Speaker 2',\n",
       "  'Sure do. And a lot of experience blowing things up! Haha. Bora bora is nice.'),\n",
       " ('Speaker 1', \"I've been working non stop crazy hours and need a break.\"),\n",
       " ('Speaker 2', 'The best breaks are spent with cute cuddly kittens.'),\n",
       " ('Speaker 1', 'Bora bora sounds nice, you have been there before?'),\n",
       " ('Speaker 2', 'Nope... Just sounds nice, and repetitive. Bora... Bora. Ha!'),\n",
       " ('Speaker 1', 'Kittens really? I rather be at the beach.'),\n",
       " ('Speaker 2', 'Only if the beach was covered in kittens!'),\n",
       " ('Speaker 1', 'That would be a sight to see.'),\n",
       " ('Speaker 2', 'Or maybe brownies... I love chocolate.'),\n",
       " ('Speaker 1', \"I love brownies too but I haven't quite perfected mine yet.\"),\n",
       " ('Speaker 2', \"Well I'm available to taste test!\"),\n",
       " ('Nobody', 'new session')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msc_session.history[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"I am an assistant with the following persona: I'm a perfectionist. If things aren't done right I'll redo them again and again. I take forever to get tasks done so I start early and clock out late. I work too much. I think I need a vacation. I've been working a lot of extra hours. I want to break from my non-stop work. I like going to the beach. I love brownies.\"},\n",
       " {'role': 'system',\n",
       "  'content': \"The user has the following persona: I served or serve in the military. I've traveled the world. I've blown things up. I've never been to Bora Bora. I love chocolate.\"},\n",
       " {'role': 'system', 'content': '2 days ago'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'I need some advice on where to go on vacation, have you been anywhere lately?'},\n",
       " {'role': 'user', 'content': \"I have been all over the world. I'm military.\"},\n",
       " {'role': 'assistant',\n",
       "  'content': 'That is good you have alot of travel experience'},\n",
       " {'role': 'user',\n",
       "  'content': 'Sure do. And a lot of experience blowing things up! Haha. Bora bora is nice.'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I've been working non stop crazy hours and need a break.\"},\n",
       " {'role': 'user',\n",
       "  'content': 'The best breaks are spent with cute cuddly kittens.'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Bora bora sounds nice, you have been there before?'},\n",
       " {'role': 'user',\n",
       "  'content': 'Nope... Just sounds nice, and repetitive. Bora... Bora. Ha!'},\n",
       " {'role': 'assistant', 'content': 'Kittens really? I rather be at the beach.'},\n",
       " {'role': 'user', 'content': 'Only if the beach was covered in kittens!'},\n",
       " {'role': 'assistant', 'content': 'That would be a sight to see.'},\n",
       " {'role': 'user', 'content': 'Or maybe brownies... I love chocolate.'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I love brownies too but I haven't quite perfected mine yet.\"},\n",
       " {'role': 'user', 'content': \"Well I'm available to taste test!\"},\n",
       " {'role': 'system', 'content': 'new session'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_messages(msc_session.history[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Speaker 1', 'Are you still in the military?')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msc_session.next_utterance[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [1, 2, 3, 4]\n",
    "l[2:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-7uJWml2EuJpWcfM9uzqx3leSVnQXb\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1693655788,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Yes, I am an AI assistant working on behalf of the military. How can I assist you today?\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 380,\n",
      "    \"completion_tokens\": 21,\n",
      "    \"total_tokens\": 401\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, I am an AI assistant working on behalf of the military. How can I assist you today?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_response(msc_session.history[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
