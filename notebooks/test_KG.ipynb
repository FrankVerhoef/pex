{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b999fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, PretrainedConfig, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4408ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.knowledge_grounded_generator.kg_model import KnowledgeGroundedDecoder, KG_loss\n",
    "from models.knowledge_grounded_generator.kg_agent import KG_enriched_MSC_Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cc8b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", padding_side='left')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "opt = {\n",
    "    \"num_hops\": 2,\n",
    "    \"aggregate_method\": \"max\",\n",
    "    \"alpha\": 0.7,\n",
    "    \"beta\": 0.2,\n",
    "    \"gamma\": 0.33,\n",
    "    'fixed_lm': False,\n",
    "    'block_src': False,\n",
    "    'gate': 0.0 # Gate=0.0 means output should be equal to regular GPT2 output\n",
    "}\n",
    "\n",
    "model = KnowledgeGroundedDecoder(opt, tokenizer, config=PretrainedConfig())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a51f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gpt2model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eec5b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_dataset = {\n",
    "    'kg_datadir': '/users/FrankVerhoef/Programming/Project_AI/ParlAI/data/kg_data/', \n",
    "    'dataset_concepts': 'total_concepts.txt', \n",
    "    'kg': 'kg.graph-sm', \n",
    "    \"speaker_prefixes\": None,\n",
    "    \"include_persona\": False,\n",
    "    \"max_concepts\": 256,\n",
    "    \"max_triples\": 768,\n",
    "    \"max_branch\": 64,\n",
    "    \"overlapping_concepts\": \"excl-src-in-tgt\",\n",
    "    \"num_hops\": 2,\n",
    "}\n",
    "\n",
    "datapath = '/Users/FrankVerhoef/Programming/PEX/data/msc/msc_dialogue/session_2/train.txt'\n",
    "dataset = KG_enriched_MSC_Session(\n",
    "    opt_dataset, \n",
    "    datapath, \n",
    "    tokenizer, \n",
    "    max_samples=None, \n",
    "    batch_format=\"huggingface\", \n",
    "    batch_pad_id=tokenizer.pad_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b396184",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mini_dataset:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.data = [\n",
    "            {\n",
    "                \"text\": \"I like my mother and sister. It is good to be with them.\", \n",
    "                \"labels\": [\"Your family is important since birth\"],\n",
    "            }, {\n",
    "                \"text\": \"Shall we play soccer?\", \n",
    "                \"labels\": [\"It is fun and a great sport to play as a team\"],\n",
    "            }, {\n",
    "                \"text\": \"The dinner was great, but now I want to go home.\", \n",
    "                \"labels\": [\"Yes, the food was delicious\"],\n",
    "            }\n",
    "        ]\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]['text'], self.data[i]['labels']\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "testdata = Mini_dataset()\n",
    "enriched = [(*testdata[i], dataset._get_kg_info(*testdata[i])) for i in range(len(testdata))]\n",
    "enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1418015",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(text=[testdata[i][0] for i in range(len(testdata))], padding=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a85e260",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = dataset.batchify(enriched)\n",
    "inputs, labels, kg_input = batch\n",
    "L = inputs.input_ids.shape[1]\n",
    "input_ids = inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacb35e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(\n",
    "    inputs=input_ids,\n",
    "    kg_input=kg_input,\n",
    "    generation_config=GenerationConfig(\n",
    "        pad_token_id=model.gpt2model.config.eos_token_id,\n",
    "        output_hidden_states=True,\n",
    "        use_cache=True,\n",
    "        num_beams=1,\n",
    "        do_sample=False,\n",
    "        max_new_tokens=10\n",
    "    )\n",
    ")\n",
    "for context, out in zip(enriched, output):\n",
    "    print(\"Context:  \", context[0])\n",
    "#     print(\"Label:    \", context[1])\n",
    "    print(\"Tensor:   \", out)\n",
    "    print(\"Response: \", dataset.tokenizer.batch_decode(out))\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2762304",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.gpt2model.generate(\n",
    "    inputs=input_ids,\n",
    "    generation_config=GenerationConfig(\n",
    "        pad_token_id=model.gpt2model.config.eos_token_id,\n",
    "        output_hidden_states=True,\n",
    "        use_cache=True,\n",
    "        num_beams=1,\n",
    "        do_sample=False,\n",
    "        max_new_tokens=10\n",
    "    )\n",
    ")\n",
    "for context, out in zip(enriched, output):\n",
    "    print(\"Context:  \", context[0])\n",
    "#     print(\"Label:    \", context[1])\n",
    "    print(\"Tensor:   \", out)\n",
    "    print(\"Response: \", dataset.tokenizer.batch_decode(out))\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2caee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.forward(\n",
    "    input_ids=inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    kg_input=kg_input\n",
    ")\n",
    "print(inputs.input_ids)\n",
    "print(inputs.attention_mask)\n",
    "print(output.last_hidden_state.shape)\n",
    "print(output.logits.argmax(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e9dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = inputs.attention_mask\n",
    "position_ids = (torch.cumsum(attention_mask, dim=1) - 1).clip(0)\n",
    "position_ids = position_ids[:, -input_ids.shape[1]:]\n",
    "output = model.gpt2model.forward(\n",
    "    input_ids=input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    position_ids=position_ids\n",
    ")\n",
    "print(output.logits.argmax(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bf269c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
