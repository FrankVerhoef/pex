{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f9b999fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer\n",
    "from transformers.generation.logits_process import LogitsProcessor, LogitsProcessorList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4408ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.knowledge_grounded_generator.kg_model import KnowledgeGroundedDecoder, KG_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "95cc8b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-15 21:10:22,359 INFO     | Initialized TripleEncoder\n",
      "2023-03-15 21:10:22,368 INFO     | Initialized KnowledgeGroundedDecoder\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", padding_side='left')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "opt = {\n",
    "    \"num_hops\": 2,\n",
    "    \"aggregate_method\": \"max\",\n",
    "    \"embedding_size\": 768,\n",
    "    \"alpha\": 0.7,\n",
    "    \"beta\": 0.2,\n",
    "    \"gamma\": 0.33,\n",
    "    'fixed_lm': False,\n",
    "    'block_src': False,\n",
    "    'gate': None\n",
    "}\n",
    "\n",
    "model = KnowledgeGroundedDecoder(opt, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "95a51f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGroundedDecoder(\n",
       "  (gpt2model): GPT2LMHeadModel(\n",
       "    (transformer): GPT2Model(\n",
       "      (wte): Embedding(50257, 768)\n",
       "      (wpe): Embedding(1024, 768)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-11): 12 x GPT2Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  )\n",
       "  (triple_encoder): TripleEncoder(\n",
       "    (concept_embd): Embedding(50257, 768)\n",
       "    (relation_embd): Embedding(69, 768)\n",
       "    (W_s): ModuleList(\n",
       "      (0-1): 2 x Linear(in_features=768, out_features=768, bias=False)\n",
       "    )\n",
       "    (W_n): ModuleList(\n",
       "      (0-1): 2 x Linear(in_features=768, out_features=768, bias=False)\n",
       "    )\n",
       "    (W_r): ModuleList(\n",
       "      (0-1): 2 x Linear(in_features=768, out_features=768, bias=False)\n",
       "    )\n",
       "    (act): ReLU()\n",
       "  )\n",
       "  (triple_linear): Linear(in_features=2304, out_features=768, bias=False)\n",
       "  (gate_linear): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ba8fe74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gpt2model.generation_config\n",
    "model.gpt2model.generation_config.pad_token_id = model.gpt2model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "165a5750",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"what should i do\"\n",
    "s2 = \"the wheather\"\n",
    "enc = tokenizer([s, s2], padding=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "688133d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[10919,   815,  1312,   466],\n",
       "        [50256,  1169,   483,  1032]]), 'attention_mask': tensor([[1, 1, 1, 1],\n",
       "        [0, 1, 1, 1]])}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a69fbf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "gen = model.gpt2model.generate(**enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4e173d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomLogitsProcessor(LogitsProcessor):\n",
    "    def __init__(self):\n",
    "        self.call_counter=0\n",
    "        pass\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor):\n",
    "        self.call_counter += 1\n",
    "        print(self.call_counter, input_ids)\n",
    "#         scores = torch.zeros_like(scores)\n",
    "        scores[:, 1:] = scores[:, :-1]\n",
    "#         print(scores.shape)\n",
    "#         scores[0, 50] = 10\n",
    "        return scores # Minimally working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "687db4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tensor([[10919,   815,  1312,   466],\n",
      "        [50256,  1169,   483,  1032]])\n",
      "2 tensor([[10919,   815,  1312,   466,   352],\n",
      "        [50256,  1169,   483,  1032,    83]])\n",
      "3 tensor([[10919,   815,  1312,   466,   352,    14],\n",
      "        [50256,  1169,   483,  1032,    83,   287]])\n",
      "4 tensor([[10919,   815,  1312,   466,   352,    14,    18],\n",
      "        [50256,  1169,   483,  1032,    83,   287,   263]])\n",
      "5 tensor([[10919,   815,  1312,   466,   352,    14,    18,   287],\n",
      "        [50256,  1169,   483,  1032,    83,   287,   263,   325]])\n",
      "6 tensor([[10919,   815,  1312,   466,   352,    14,    18,   287,   263],\n",
      "        [50256,  1169,   483,  1032,    83,   287,   263,   325,   322]])\n",
      "7 tensor([[10919,   815,  1312,   466,   352,    14,    18,   287,   263,   325],\n",
      "        [50256,  1169,   483,  1032,    83,   287,   263,   325,   322,    12]])\n",
      "8 tensor([[10919,   815,  1312,   466,   352,    14,    18,   287,   263,   325,\n",
      "            31],\n",
      "        [50256,  1169,   483,  1032,    83,   287,   263,   325,   322,    12,\n",
      "            84]])\n",
      "9 tensor([[10919,   815,  1312,   466,   352,    14,    18,   287,   263,   325,\n",
      "            31,    83],\n",
      "        [50256,  1169,   483,  1032,    83,   287,   263,   325,   322,    12,\n",
      "            84,    13]])\n",
      "10 tensor([[10919,   815,  1312,   466,   352,    14,    18,   287,   263,   325,\n",
      "            31,    83,    14],\n",
      "        [50256,  1169,   483,  1032,    83,   287,   263,   325,   322,    12,\n",
      "            84,    13,   199]])\n",
      "11 tensor([[10919,   815,  1312,   466,   352,    14,    18,   287,   263,   325,\n",
      "            31,    83,    14,    84],\n",
      "        [50256,  1169,   483,  1032,    83,   287,   263,   325,   322,    12,\n",
      "            84,    13,   199,    14]])\n",
      "12 tensor([[10919,   815,  1312,   466,   352,    14,    18,   287,   263,   325,\n",
      "            31,    83,    14,    84,    15],\n",
      "        [50256,  1169,   483,  1032,    83,   287,   263,   325,   322,    12,\n",
      "            84,    13,   199,    14,    73]])\n",
      "13 tensor([[10919,   815,  1312,   466,   352,    14,    18,   287,   263,   325,\n",
      "            31,    83,    14,    84,    15,    15],\n",
      "        [50256,  1169,   483,  1032,    83,   287,   263,   325,   322,    12,\n",
      "            84,    13,   199,    14,    73,    15]])\n",
      "14 tensor([[10919,   815,  1312,   466,   352,    14,    18,   287,   263,   325,\n",
      "            31,    83,    14,    84,    15,    15,    15],\n",
      "        [50256,  1169,   483,  1032,    83,   287,   263,   325,   322,    12,\n",
      "            84,    13,   199,    14,    73,    15,    15]])\n",
      "15 tensor([[10919,   815,  1312,   466,   352,    14,    18,   287,   263,   325,\n",
      "            31,    83,    14,    84,    15,    15,    15,    15],\n",
      "        [50256,  1169,   483,  1032,    83,   287,   263,   325,   322,    12,\n",
      "            84,    13,   199,    14,    73,    15,    15,    15]])\n",
      "16 tensor([[10919,   815,  1312,   466,   352,    14,    18,   287,   263,   325,\n",
      "            31,    83,    14,    84,    15,    15,    15,    15,    15],\n",
      "        [50256,  1169,   483,  1032,    83,   287,   263,   325,   322,    12,\n",
      "            84,    13,   199,    14,    73,    15,    15,    15,    15]])\n"
     ]
    }
   ],
   "source": [
    "logits_processor_list = LogitsProcessorList([\n",
    "    MyCustomLogitsProcessor(),\n",
    "])\n",
    "gen = model.gpt2model.generate(\n",
    "   **enc,\n",
    "   num_beams=1, do_sample=False,\n",
    "   return_dict_in_generate=False,\n",
    "   output_scores=False,\n",
    "   logits_processor=logits_processor_list, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "88c958fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10919,   815,  1312,   466,   351,   428,    30,   198,   198,    40,\n",
       "          1101,   407,  1654,   644,   284,   466,   351,   428,    13,   198],\n",
       "        [50256,  1169,   483,  1032,    82,    11,   290,   262,   584,   734,\n",
       "           389,   262,  3392,   326,   389,   407,    13,   198,   198,   464]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d0f55663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what should i do 1/3 inerse@t/u000000',\n",
       " '<|endoftext|>the wheathert inerseow-u.\\x0b/j00000']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a57d8206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10919,   815,  1312,   466,   351,   428,    30,   198,   198,    40,\n",
       "          1101,   407,  1654,   644,   284,   466,   351,   428,    13,   198],\n",
       "        [50256,  1169,   483,  1032,    82,    11,   290,   262,   584,   734,\n",
       "           389,   262,  3392,   326,   389,   407,    13,   198,   198,   464]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec48761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
