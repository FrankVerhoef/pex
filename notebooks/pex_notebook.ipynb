{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f97ae051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "456564fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# this ensures that the current MacOS version is at least 12.3+\n",
    "print(torch.backends.mps.is_available())\n",
    "\n",
    "# this ensures that the current current PyTorch installation was built with MPS activated.\n",
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66965eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed14f75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### Class to read the MSC summary dataset, and preprocess the data.\n",
    "###\n",
    "\n",
    "special_tokens = ['<P0>', '<P1>', '<SOS>', '<EOS>', '<UNK>', '<PAD>']\n",
    "\n",
    "class MSC_Turns(Dataset):\n",
    "    \n",
    "    def __init__(self, path, len_context=2):\n",
    "        super(MSC_Turns, self).__init__()\n",
    "        dialogues = []\n",
    "        with open(path, \"r\") as f:\n",
    "            for line in f:\n",
    "                dialogues.append(json.loads(line))\n",
    "        self.len_context = len_context\n",
    "        self.turns, self.personas = self.transform(dialogues)\n",
    "        \n",
    "    def transform(self, dialogues):\n",
    "        turns, personas = [], []\n",
    "        \n",
    "        for d in dialogues:\n",
    "            for i in range(len(d[\"dialog\"]) - self.len_context + 1):\n",
    "                \n",
    "                turn = \"\"\n",
    "                for j in range(self.len_context):\n",
    "                    turn += '<P{}> '.format((self.len_context - j) % 2)\n",
    "                    turn += d[\"dialog\"][i+j].get(\"text\",\"\") + ' '\n",
    "                turn += '<EOS>'\n",
    "                turns.append(turn)\n",
    "                persona = ''\n",
    "                if \"persona_text\" in d[\"dialog\"][i+self.len_context-1].keys():\n",
    "                    persona += d[\"dialog\"][i+self.len_context-1][\"persona_text\"] + ' '\n",
    "                persona += '<EOS>'\n",
    "                personas.append(persona)\n",
    "        \n",
    "        return turns, personas\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(turns)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.turns[i], self.personas[i]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24f00cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/Users/FrankVerhoef/Programming/PEX/data/msc/msc_personasummary/session_1/train.txt'\n",
    "msc_turns = MSC_Turns(datapath, len_context=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b54b89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<P0> I need some advice on where to go on vacation, have you been anywhere lately? <P1> I have been all over the world. I'm military. <EOS>\n",
      "I served or serve in the military. I've traveled the world. <EOS>\n",
      "----------------------------------------\n",
      "<P0> I have been all over the world. I'm military. <P1> That is good you have alot of travel experience <EOS>\n",
      "<EOS>\n",
      "----------------------------------------\n",
      "<P0> That is good you have alot of travel experience <P1> Sure do. And a lot of experience blowing things up! Haha. Bora bora is nice. <EOS>\n",
      "I've blown things up. <EOS>\n",
      "----------------------------------------\n",
      "<P0> Sure do. And a lot of experience blowing things up! Haha. Bora bora is nice. <P1> I've been working non stop crazy hours and need a break. <EOS>\n",
      "I've been working a lot of extra hours. I want to break from my non-stop work. <EOS>\n",
      "----------------------------------------\n",
      "<P0> I've been working non stop crazy hours and need a break. <P1> The best breaks are spent with cute cuddly kittens. <EOS>\n",
      "<EOS>\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(msc_turns[i][0])\n",
    "    print(msc_turns[i][1])\n",
    "    print('-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc77773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.symbols import ORTH\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable = ['ner', 'tagger', 'parser', 'textcat'])\n",
    "\n",
    "for t in special_tokens:\n",
    "    nlp.tokenizer.add_special_case(t, [{ORTH: t}])\n",
    "\n",
    "\n",
    "def build_dict(dataset, max=1000):\n",
    "    vocab = dict()\n",
    "    for turn, persona in dataset: \n",
    "        tokens = nlp(turn + ' ' + persona)\n",
    "        for t in tokens:\n",
    "            if t.text in special_tokens:\n",
    "                pass\n",
    "            elif t.text in vocab.keys():\n",
    "                vocab[t.text] += 1\n",
    "            else:\n",
    "                vocab[t.text] = 1\n",
    "        if len(vocab.keys()) >= max: break\n",
    "    vocab = dict(sorted(vocab.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "    return list(vocab.keys())[:max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a7f68f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/frankverhoef/opt/miniconda3/envs/pex/lib/python3.9/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1006\n"
     ]
    }
   ],
   "source": [
    "ind2tok = build_dict(msc_turns, max=1000)\n",
    "ind2tok.extend(special_tokens)\n",
    "tok2ind = {token: i for i, token in enumerate(ind2tok)}\n",
    "\n",
    "def tok2vec(tokens):\n",
    "    return [tok2ind.get(t.text, tok2ind['<UNK>']) for t in tokens]\n",
    "\n",
    "def vec2tok(vec):\n",
    "    return [ind2tok[i] for i in vec]\n",
    "\n",
    "print(len(ind2tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a42ff3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSC_Summaries(Dataset):\n",
    "    \n",
    "    def __init__(self, path, len_context, tokenizer, tok2ind):\n",
    "    \n",
    "        self.dataset = MSC_Turns(path, len_context)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tok2ind = tok2ind\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        tokens_x = nlp(self.dataset[i][0])\n",
    "        tokens_y = nlp(self.dataset[i][1])\n",
    "        x = torch.tensor(tok2vec(tokens_x))\n",
    "        y = torch.tensor(tok2vec(tokens_y))\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d86b5658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embed = self.embedding(x).view(1, 1, -1)\n",
    "        output, hidden_new = self.gru(embed, hidden)\n",
    "        return output, hidden_new\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        output = self.embedding(x).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden_new = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden_new\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfa56361",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(len(ind2tok), 30)\n",
    "decoder = DecoderRNN(30, len(ind2tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31faeb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x):\n",
    "\n",
    "    hidden = encoder.initHidden()\n",
    "    for i in range(x.size(0)):\n",
    "        output, hidden = encoder(x[i], hidden)\n",
    "        \n",
    "    return output, hidden\n",
    "\n",
    "def decode(hidden, target=None, teacher_forcing=False, max=10):\n",
    "    \n",
    "    decoder_input = torch.full(size=(1, hidden.size(1)), fill_value=tok2ind['<SOS>'])\n",
    "    out = torch.zeros(max, hidden.size(1), len(ind2tok))\n",
    "    for i in range(max):\n",
    "        out[i], hidden = decoder(decoder_input, hidden)\n",
    "        if teacher_forcing:\n",
    "            if i >= target.size(0) - 1: break\n",
    "            decoder_input = target[i]\n",
    "        else:\n",
    "            decoder_input = out[i].argmax(dim=-1).view(1, -1)\n",
    "        \n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26f8f9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank vacation announcer announcer computer computer catch seeking Both Both\n",
      "I love chocolate . <EOS>\n",
      "----------------------------------------\n",
      "3 Thank announcer computer catch seeking Both Both Both Both\n",
      "I love brownies . <EOS>\n",
      "----------------------------------------\n",
      "Thank doing doing wheelchair sick sick Went 2 computer computer\n",
      "<EOS>\n",
      "----------------------------------------\n",
      "Thank announcer computer computer sleep work computer computer sleep work\n",
      "I have an exam soon . <EOS>\n",
      "----------------------------------------\n",
      "3 Thank fact announcer announcer computer catch seeking Both Both\n",
      "I have three dogs . <EOS>\n",
      "----------------------------------------\n",
      "Thank doing doing wheelchair sick sick Went 2 computer computer\n",
      "I finish school in September . I do n't have any dogs . <EOS>\n",
      "----------------------------------------\n",
      "Thank doing only sick lessons Both Both Both Both Both\n",
      "<EOS>\n",
      "----------------------------------------\n",
      "Thank doing only sick lessons Both Both Both Both Both\n",
      "I plan on getting a job in teaching . <EOS>\n",
      "----------------------------------------\n",
      "3 Thank fact announcer announcer computer catch seeking Both Both\n",
      "I play the drums . <EOS>\n",
      "----------------------------------------\n",
      "3 shop computer sleep sleep work computer computer sleep work\n",
      "<EOS>\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset = MSC_Summaries(datapath, len_context=2, tokenizer=nlp, tok2ind=tok2ind)\n",
    "\n",
    "for i in range(10,20):\n",
    "    _, hidden = encode(dataset[i][0])\n",
    "#     dec_out = decode(hidden, dataset[i][1], teacher_forcing=True)\n",
    "    dec_out = decode(hidden)\n",
    "    dec = torch.transpose(dec_out.argmax(dim=-1), 1, 0)[0]\n",
    "    response = ' '.join([ind2tok[i] for i in dec])\n",
    "    print(response)\n",
    "    print(' '.join(vec2tok(dataset[i][1])))\n",
    "    print('-' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88aaeaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " 'I',\n",
       " 'to',\n",
       " 'a',\n",
       " 'you',\n",
       " ',',\n",
       " '?',\n",
       " 'my',\n",
       " '!',\n",
       " 'do',\n",
       " 'the',\n",
       " 'have',\n",
       " 'is',\n",
       " 'am',\n",
       " 'in',\n",
       " 'like',\n",
       " 'and',\n",
       " 'for',\n",
       " 'that',\n",
       " 'love']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2tok[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18625a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "def train_step(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    _, hidden = encode(input_tensor)\n",
    "    decoder_output = decode(hidden, target=target_tensor, teacher_forcing=True, max=target_tensor.size(0))\n",
    "    loss = criterion(decoder_output.squeeze(), target_tensor.squeeze())\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bddd31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(encoder, decoder, dataset, max_steps=1000, print_every=1000, learning_rate=0.01):\n",
    "\n",
    "    print_loss_total = 0\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for step, (x, y) in enumerate(dataset):\n",
    "\n",
    "        loss = train_step(x.view(-1, 1), y.view(-1, 1), encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "\n",
    "        if (step + 1) % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print(step + 1, print_loss_avg)\n",
    "            print_loss_total = 0\n",
    "        if step >= max_steps: break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "63b0d30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 6.422246384620666\n",
      "200 4.743728432059288\n",
      "300 4.321910395920277\n",
      "400 3.416451494693756\n",
      "500 3.403665184676647\n",
      "600 2.8189416801929474\n",
      "700 3.0073387691378595\n",
      "800 2.5979190544784068\n",
      "900 2.6689348646998408\n",
      "1000 2.6499454717338087\n"
     ]
    }
   ],
   "source": [
    "train(encoder, decoder, dataset, max_steps=1000, print_every=100, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e0765fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6227a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = torch.randn(3,5)\n",
    "t = torch.tensor([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5b8b7065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4610)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(o,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8b6c2327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5]), torch.Size([3]))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.shape, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c399fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
